{"implementation_name": "baseline", "gpu_name": "NVIDIA RTX A6000", "gpu_total_vram": 51033931776, "python_version": "3.11.14", "pytorch_version": "2.9.1+cu128", "cuda_version": "12.8", "dtype": "bfloat16", "model_config": {"n_layer": 24, "n_head": 16, "n_embd": 1024, "block_size": 1024, "vocab_size": 50257, "dropout": 0.0, "bias": true, "kv_cache_quant": false, "cross_layer_sharing": false}, "prompt_length": 32, "batch_size": 1, "seed": 1337, "pretrained": "gpt2-medium", "benchmark_name": "latency_vs_T", "version": "v0", "version_description": "No cache (baseline)", "use_cache": false, "kv_cache_quant": false, "cross_layer_sharing": false, "T": 32, "time_total_ms_median": 92.14361572265625, "time_total_ms_mean": 92.04418182373047, "time_total_ms_std": 1.0527043342590332, "time_per_token_ms_median": 2.879487991333008, "time_per_token_ms_std": 0.03289701044559479, "n_samples": 19, "n_outliers_removed": 1}
{"implementation_name": "baseline", "gpu_name": "NVIDIA RTX A6000", "gpu_total_vram": 51033931776, "python_version": "3.11.14", "pytorch_version": "2.9.1+cu128", "cuda_version": "12.8", "dtype": "bfloat16", "model_config": {"n_layer": 24, "n_head": 16, "n_embd": 1024, "block_size": 1024, "vocab_size": 50257, "dropout": 0.0, "bias": true, "kv_cache_quant": false, "cross_layer_sharing": false}, "prompt_length": 32, "batch_size": 1, "seed": 1337, "pretrained": "gpt2-medium", "benchmark_name": "latency_vs_T", "version": "v0", "version_description": "No cache (baseline)", "use_cache": false, "kv_cache_quant": false, "cross_layer_sharing": false, "T": 64, "time_total_ms_median": 189.1082305908203, "time_total_ms_mean": 189.41676330566406, "time_total_ms_std": 1.0356320142745972, "time_per_token_ms_median": 2.9548161029815674, "time_per_token_ms_std": 0.01618175022304058, "n_samples": 18, "n_outliers_removed": 2}
{"implementation_name": "baseline", "gpu_name": "NVIDIA RTX A6000", "gpu_total_vram": 51033931776, "python_version": "3.11.14", "pytorch_version": "2.9.1+cu128", "cuda_version": "12.8", "dtype": "bfloat16", "model_config": {"n_layer": 24, "n_head": 16, "n_embd": 1024, "block_size": 1024, "vocab_size": 50257, "dropout": 0.0, "bias": true, "kv_cache_quant": false, "cross_layer_sharing": false}, "prompt_length": 32, "batch_size": 1, "seed": 1337, "pretrained": "gpt2-medium", "benchmark_name": "latency_vs_T", "version": "v0", "version_description": "No cache (baseline)", "use_cache": false, "kv_cache_quant": false, "cross_layer_sharing": false, "T": 96, "time_total_ms_median": 288.0849914550781, "time_total_ms_mean": 288.51611328125, "time_total_ms_std": 1.3830838203430176, "time_per_token_ms_median": 3.000885327657064, "time_per_token_ms_std": 0.0144071231285731, "n_samples": 19, "n_outliers_removed": 1}
{"implementation_name": "baseline", "gpu_name": "NVIDIA RTX A6000", "gpu_total_vram": 51033931776, "python_version": "3.11.14", "pytorch_version": "2.9.1+cu128", "cuda_version": "12.8", "dtype": "bfloat16", "model_config": {"n_layer": 24, "n_head": 16, "n_embd": 1024, "block_size": 1024, "vocab_size": 50257, "dropout": 0.0, "bias": true, "kv_cache_quant": false, "cross_layer_sharing": false}, "prompt_length": 32, "batch_size": 1, "seed": 1337, "pretrained": "gpt2-medium", "benchmark_name": "latency_vs_T", "version": "v0", "version_description": "No cache (baseline)", "use_cache": false, "kv_cache_quant": false, "cross_layer_sharing": false, "T": 128, "time_total_ms_median": 399.8464050292969, "time_total_ms_mean": 400.05047607421875, "time_total_ms_std": 1.8676939010620117, "time_per_token_ms_median": 3.123800039291382, "time_per_token_ms_std": 0.014591358602046967, "n_samples": 20, "n_outliers_removed": 0}
{"implementation_name": "baseline", "gpu_name": "NVIDIA RTX A6000", "gpu_total_vram": 51033931776, "python_version": "3.11.14", "pytorch_version": "2.9.1+cu128", "cuda_version": "12.8", "dtype": "bfloat16", "model_config": {"n_layer": 24, "n_head": 16, "n_embd": 1024, "block_size": 1024, "vocab_size": 50257, "dropout": 0.0, "bias": true, "kv_cache_quant": false, "cross_layer_sharing": false}, "prompt_length": 32, "batch_size": 1, "seed": 1337, "pretrained": "gpt2-medium", "benchmark_name": "latency_vs_T", "version": "v0", "version_description": "No cache (baseline)", "use_cache": false, "kv_cache_quant": false, "cross_layer_sharing": false, "T": 160, "time_total_ms_median": 514.7597045898438, "time_total_ms_mean": 515.266357421875, "time_total_ms_std": 1.363448977470398, "time_per_token_ms_median": 3.2172481536865236, "time_per_token_ms_std": 0.008521556109189986, "n_samples": 20, "n_outliers_removed": 0}
{"implementation_name": "baseline", "gpu_name": "NVIDIA RTX A6000", "gpu_total_vram": 51033931776, "python_version": "3.11.14", "pytorch_version": "2.9.1+cu128", "cuda_version": "12.8", "dtype": "bfloat16", "model_config": {"n_layer": 24, "n_head": 16, "n_embd": 1024, "block_size": 1024, "vocab_size": 50257, "dropout": 0.0, "bias": true, "kv_cache_quant": false, "cross_layer_sharing": false}, "prompt_length": 32, "batch_size": 1, "seed": 1337, "pretrained": "gpt2-medium", "benchmark_name": "latency_vs_T", "version": "v0", "version_description": "No cache (baseline)", "use_cache": false, "kv_cache_quant": false, "cross_layer_sharing": false, "T": 192, "time_total_ms_median": 647.3633422851562, "time_total_ms_mean": 647.4842529296875, "time_total_ms_std": 1.1962428092956543, "time_per_token_ms_median": 3.3716840744018555, "time_per_token_ms_std": 0.006230431298414866, "n_samples": 19, "n_outliers_removed": 1}
{"implementation_name": "baseline", "gpu_name": "NVIDIA RTX A6000", "gpu_total_vram": 51033931776, "python_version": "3.11.14", "pytorch_version": "2.9.1+cu128", "cuda_version": "12.8", "dtype": "bfloat16", "model_config": {"n_layer": 24, "n_head": 16, "n_embd": 1024, "block_size": 1024, "vocab_size": 50257, "dropout": 0.0, "bias": true, "kv_cache_quant": false, "cross_layer_sharing": false}, "prompt_length": 32, "batch_size": 1, "seed": 1337, "pretrained": "gpt2-medium", "benchmark_name": "latency_vs_T", "version": "v0", "version_description": "No cache (baseline)", "use_cache": false, "kv_cache_quant": false, "cross_layer_sharing": false, "T": 224, "time_total_ms_median": 787.70263671875, "time_total_ms_mean": 787.5082397460938, "time_total_ms_std": 1.0693000555038452, "time_per_token_ms_median": 3.5165296282087053, "time_per_token_ms_std": 0.004773660962070737, "n_samples": 20, "n_outliers_removed": 0}
{"implementation_name": "baseline", "gpu_name": "NVIDIA RTX A6000", "gpu_total_vram": 51033931776, "python_version": "3.11.14", "pytorch_version": "2.9.1+cu128", "cuda_version": "12.8", "dtype": "bfloat16", "model_config": {"n_layer": 24, "n_head": 16, "n_embd": 1024, "block_size": 1024, "vocab_size": 50257, "dropout": 0.0, "bias": true, "kv_cache_quant": false, "cross_layer_sharing": false}, "prompt_length": 32, "batch_size": 1, "seed": 1337, "pretrained": "gpt2-medium", "benchmark_name": "latency_vs_T", "version": "v0", "version_description": "No cache (baseline)", "use_cache": false, "kv_cache_quant": false, "cross_layer_sharing": false, "T": 256, "time_total_ms_median": 937.0684204101562, "time_total_ms_mean": 937.0865478515625, "time_total_ms_std": 1.260332703590393, "time_per_token_ms_median": 3.660423517227173, "time_per_token_ms_std": 0.004923174623399973, "n_samples": 20, "n_outliers_removed": 0}
{"implementation_name": "baseline", "gpu_name": "NVIDIA RTX A6000", "gpu_total_vram": 51033931776, "python_version": "3.11.14", "pytorch_version": "2.9.1+cu128", "cuda_version": "12.8", "dtype": "bfloat16", "model_config": {"n_layer": 24, "n_head": 16, "n_embd": 1024, "block_size": 1024, "vocab_size": 50257, "dropout": 0.0, "bias": true, "kv_cache_quant": false, "cross_layer_sharing": false}, "prompt_length": 32, "batch_size": 1, "seed": 1337, "pretrained": "gpt2-medium", "benchmark_name": "latency_vs_T", "version": "v0", "version_description": "No cache (baseline)", "use_cache": false, "kv_cache_quant": false, "cross_layer_sharing": false, "T": 320, "time_total_ms_median": 1266.72900390625, "time_total_ms_mean": 1266.5091552734375, "time_total_ms_std": 1.3269160985946655, "time_per_token_ms_median": 3.9585281372070313, "time_per_token_ms_std": 0.004146612808108329, "n_samples": 18, "n_outliers_removed": 2}
{"implementation_name": "baseline", "gpu_name": "NVIDIA RTX A6000", "gpu_total_vram": 51033931776, "python_version": "3.11.14", "pytorch_version": "2.9.1+cu128", "cuda_version": "12.8", "dtype": "bfloat16", "model_config": {"n_layer": 24, "n_head": 16, "n_embd": 1024, "block_size": 1024, "vocab_size": 50257, "dropout": 0.0, "bias": true, "kv_cache_quant": false, "cross_layer_sharing": false}, "prompt_length": 32, "batch_size": 1, "seed": 1337, "pretrained": "gpt2-medium", "benchmark_name": "latency_vs_T", "version": "v0", "version_description": "No cache (baseline)", "use_cache": false, "kv_cache_quant": false, "cross_layer_sharing": false, "T": 384, "time_total_ms_median": 1628.078125, "time_total_ms_mean": 1628.2021484375, "time_total_ms_std": 1.1062121391296387, "time_per_token_ms_median": 4.239786783854167, "time_per_token_ms_std": 0.002880760778983434, "n_samples": 17, "n_outliers_removed": 3}
{"implementation_name": "baseline", "gpu_name": "NVIDIA RTX A6000", "gpu_total_vram": 51033931776, "python_version": "3.11.14", "pytorch_version": "2.9.1+cu128", "cuda_version": "12.8", "dtype": "bfloat16", "model_config": {"n_layer": 24, "n_head": 16, "n_embd": 1024, "block_size": 1024, "vocab_size": 50257, "dropout": 0.0, "bias": true, "kv_cache_quant": false, "cross_layer_sharing": false}, "prompt_length": 32, "batch_size": 1, "seed": 1337, "pretrained": "gpt2-medium", "benchmark_name": "latency_vs_T", "version": "v0", "version_description": "No cache (baseline)", "use_cache": false, "kv_cache_quant": false, "cross_layer_sharing": false, "T": 448, "time_total_ms_median": 2014.9739990234375, "time_total_ms_mean": 2015.2816162109375, "time_total_ms_std": 1.2261894941329956, "time_per_token_ms_median": 4.497709819248745, "time_per_token_ms_std": 0.0027370301208325793, "n_samples": 20, "n_outliers_removed": 0}
{"implementation_name": "baseline", "gpu_name": "NVIDIA RTX A6000", "gpu_total_vram": 51033931776, "python_version": "3.11.14", "pytorch_version": "2.9.1+cu128", "cuda_version": "12.8", "dtype": "bfloat16", "model_config": {"n_layer": 24, "n_head": 16, "n_embd": 1024, "block_size": 1024, "vocab_size": 50257, "dropout": 0.0, "bias": true, "kv_cache_quant": false, "cross_layer_sharing": false}, "prompt_length": 32, "batch_size": 1, "seed": 1337, "pretrained": "gpt2-medium", "benchmark_name": "latency_vs_T", "version": "v0", "version_description": "No cache (baseline)", "use_cache": false, "kv_cache_quant": false, "cross_layer_sharing": false, "T": 512, "time_total_ms_median": 2427.864990234375, "time_total_ms_mean": 2427.846923828125, "time_total_ms_std": 1.444830060005188, "time_per_token_ms_median": 4.741923809051514, "time_per_token_ms_std": 0.002821933710947633, "n_samples": 17, "n_outliers_removed": 3}
{"implementation_name": "baseline", "gpu_name": "NVIDIA RTX A6000", "gpu_total_vram": 51033931776, "python_version": "3.11.14", "pytorch_version": "2.9.1+cu128", "cuda_version": "12.8", "dtype": "bfloat16", "model_config": {"n_layer": 24, "n_head": 16, "n_embd": 1024, "block_size": 1024, "vocab_size": 50257, "dropout": 0.0, "bias": true, "kv_cache_quant": false, "cross_layer_sharing": false}, "prompt_length": 32, "batch_size": 1, "seed": 1337, "pretrained": "gpt2-medium", "benchmark_name": "latency_vs_T", "version": "v0", "version_description": "No cache (baseline)", "use_cache": false, "kv_cache_quant": false, "cross_layer_sharing": false, "T": 640, "time_total_ms_median": 3376.438232421875, "time_total_ms_mean": 3376.7705078125, "time_total_ms_std": 1.4016616344451904, "time_per_token_ms_median": 5.27568473815918, "time_per_token_ms_std": 0.00219009630382061, "n_samples": 19, "n_outliers_removed": 1}
{"implementation_name": "baseline", "gpu_name": "NVIDIA RTX A6000", "gpu_total_vram": 51033931776, "python_version": "3.11.14", "pytorch_version": "2.9.1+cu128", "cuda_version": "12.8", "dtype": "bfloat16", "model_config": {"n_layer": 24, "n_head": 16, "n_embd": 1024, "block_size": 1024, "vocab_size": 50257, "dropout": 0.0, "bias": true, "kv_cache_quant": false, "cross_layer_sharing": false}, "prompt_length": 32, "batch_size": 1, "seed": 1337, "pretrained": "gpt2-medium", "benchmark_name": "latency_vs_T", "version": "v0", "version_description": "No cache (baseline)", "use_cache": false, "kv_cache_quant": false, "cross_layer_sharing": false, "T": 768, "time_total_ms_median": 4601.03759765625, "time_total_ms_mean": 4601.14208984375, "time_total_ms_std": 1.2128814458847046, "time_per_token_ms_median": 5.990934371948242, "time_per_token_ms_std": 0.0015792727159957092, "n_samples": 18, "n_outliers_removed": 2}
{"implementation_name": "baseline", "gpu_name": "NVIDIA RTX A6000", "gpu_total_vram": 51033931776, "python_version": "3.11.14", "pytorch_version": "2.9.1+cu128", "cuda_version": "12.8", "dtype": "bfloat16", "model_config": {"n_layer": 24, "n_head": 16, "n_embd": 1024, "block_size": 1024, "vocab_size": 50257, "dropout": 0.0, "bias": true, "kv_cache_quant": false, "cross_layer_sharing": false}, "prompt_length": 32, "batch_size": 1, "seed": 1337, "pretrained": "gpt2-medium", "benchmark_name": "latency_vs_T", "version": "v0", "version_description": "No cache (baseline)", "use_cache": false, "kv_cache_quant": false, "cross_layer_sharing": false, "T": 896, "time_total_ms_median": 5919.4892578125, "time_total_ms_mean": 5919.78857421875, "time_total_ms_std": 1.6124767065048218, "time_per_token_ms_median": 6.606572832380023, "time_per_token_ms_std": 0.0017996391813669885, "n_samples": 20, "n_outliers_removed": 0}
{"implementation_name": "baseline", "gpu_name": "NVIDIA RTX A6000", "gpu_total_vram": 51033931776, "python_version": "3.11.14", "pytorch_version": "2.9.1+cu128", "cuda_version": "12.8", "dtype": "bfloat16", "model_config": {"n_layer": 24, "n_head": 16, "n_embd": 1024, "block_size": 1024, "vocab_size": 50257, "dropout": 0.0, "bias": true, "kv_cache_quant": false, "cross_layer_sharing": false}, "prompt_length": 32, "batch_size": 1, "seed": 1337, "pretrained": "gpt2-medium", "benchmark_name": "latency_vs_T", "version": "v0", "version_description": "No cache (baseline)", "use_cache": false, "kv_cache_quant": false, "cross_layer_sharing": false, "T": 1024, "time_total_ms_median": 7362.5048828125, "time_total_ms_mean": 7362.4775390625, "time_total_ms_std": 1.2018401622772217, "time_per_token_ms_median": 7.189946174621582, "time_per_token_ms_std": 0.0011736720334738493, "n_samples": 20, "n_outliers_removed": 0}
{"implementation_name": "baseline", "gpu_name": "NVIDIA RTX A6000", "gpu_total_vram": 51033931776, "python_version": "3.11.14", "pytorch_version": "2.9.1+cu128", "cuda_version": "12.8", "dtype": "bfloat16", "model_config": {"n_layer": 24, "n_head": 16, "n_embd": 1024, "block_size": 1024, "vocab_size": 50257, "dropout": 0.0, "bias": true, "kv_cache_quant": false, "cross_layer_sharing": false}, "prompt_length": 32, "batch_size": 1, "seed": 1337, "pretrained": "gpt2-medium", "benchmark_name": "latency_vs_T", "version": "v1", "version_description": "KV-cache enabled", "use_cache": true, "kv_cache_quant": false, "cross_layer_sharing": false, "T": 32, "time_total_ms_median": 103.42998504638672, "time_total_ms_mean": 103.52704620361328, "time_total_ms_std": 0.7133036255836487, "time_per_token_ms_median": 3.232187032699585, "time_per_token_ms_std": 0.02229073829948902, "n_samples": 18, "n_outliers_removed": 2}
{"implementation_name": "baseline", "gpu_name": "NVIDIA RTX A6000", "gpu_total_vram": 51033931776, "python_version": "3.11.14", "pytorch_version": "2.9.1+cu128", "cuda_version": "12.8", "dtype": "bfloat16", "model_config": {"n_layer": 24, "n_head": 16, "n_embd": 1024, "block_size": 1024, "vocab_size": 50257, "dropout": 0.0, "bias": true, "kv_cache_quant": false, "cross_layer_sharing": false}, "prompt_length": 32, "batch_size": 1, "seed": 1337, "pretrained": "gpt2-medium", "benchmark_name": "latency_vs_T", "version": "v1", "version_description": "KV-cache enabled", "use_cache": true, "kv_cache_quant": false, "cross_layer_sharing": false, "T": 64, "time_total_ms_median": 207.42962646484375, "time_total_ms_mean": 208.29525756835938, "time_total_ms_std": 2.4612293243408203, "time_per_token_ms_median": 3.2410879135131836, "time_per_token_ms_std": 0.03845670819282532, "n_samples": 20, "n_outliers_removed": 0}
{"implementation_name": "baseline", "gpu_name": "NVIDIA RTX A6000", "gpu_total_vram": 51033931776, "python_version": "3.11.14", "pytorch_version": "2.9.1+cu128", "cuda_version": "12.8", "dtype": "bfloat16", "model_config": {"n_layer": 24, "n_head": 16, "n_embd": 1024, "block_size": 1024, "vocab_size": 50257, "dropout": 0.0, "bias": true, "kv_cache_quant": false, "cross_layer_sharing": false}, "prompt_length": 32, "batch_size": 1, "seed": 1337, "pretrained": "gpt2-medium", "benchmark_name": "latency_vs_T", "version": "v1", "version_description": "KV-cache enabled", "use_cache": true, "kv_cache_quant": false, "cross_layer_sharing": false, "T": 96, "time_total_ms_median": 310.18292236328125, "time_total_ms_mean": 310.2913818359375, "time_total_ms_std": 1.1081111431121826, "time_per_token_ms_median": 3.231072107950846, "time_per_token_ms_std": 0.01154282440741857, "n_samples": 18, "n_outliers_removed": 2}
{"implementation_name": "baseline", "gpu_name": "NVIDIA RTX A6000", "gpu_total_vram": 51033931776, "python_version": "3.11.14", "pytorch_version": "2.9.1+cu128", "cuda_version": "12.8", "dtype": "bfloat16", "model_config": {"n_layer": 24, "n_head": 16, "n_embd": 1024, "block_size": 1024, "vocab_size": 50257, "dropout": 0.0, "bias": true, "kv_cache_quant": false, "cross_layer_sharing": false}, "prompt_length": 32, "batch_size": 1, "seed": 1337, "pretrained": "gpt2-medium", "benchmark_name": "latency_vs_T", "version": "v1", "version_description": "KV-cache enabled", "use_cache": true, "kv_cache_quant": false, "cross_layer_sharing": false, "T": 128, "time_total_ms_median": 412.33306884765625, "time_total_ms_mean": 412.9219665527344, "time_total_ms_std": 2.9197421073913574, "time_per_token_ms_median": 3.2213521003723145, "time_per_token_ms_std": 0.02281048521399498, "n_samples": 20, "n_outliers_removed": 0}
{"implementation_name": "baseline", "gpu_name": "NVIDIA RTX A6000", "gpu_total_vram": 51033931776, "python_version": "3.11.14", "pytorch_version": "2.9.1+cu128", "cuda_version": "12.8", "dtype": "bfloat16", "model_config": {"n_layer": 24, "n_head": 16, "n_embd": 1024, "block_size": 1024, "vocab_size": 50257, "dropout": 0.0, "bias": true, "kv_cache_quant": false, "cross_layer_sharing": false}, "prompt_length": 32, "batch_size": 1, "seed": 1337, "pretrained": "gpt2-medium", "benchmark_name": "latency_vs_T", "version": "v1", "version_description": "KV-cache enabled", "use_cache": true, "kv_cache_quant": false, "cross_layer_sharing": false, "T": 160, "time_total_ms_median": 510.45068359375, "time_total_ms_mean": 510.696044921875, "time_total_ms_std": 2.908270835876465, "time_per_token_ms_median": 3.1903167724609376, "time_per_token_ms_std": 0.018176692724227905, "n_samples": 20, "n_outliers_removed": 0}
{"implementation_name": "baseline", "gpu_name": "NVIDIA RTX A6000", "gpu_total_vram": 51033931776, "python_version": "3.11.14", "pytorch_version": "2.9.1+cu128", "cuda_version": "12.8", "dtype": "bfloat16", "model_config": {"n_layer": 24, "n_head": 16, "n_embd": 1024, "block_size": 1024, "vocab_size": 50257, "dropout": 0.0, "bias": true, "kv_cache_quant": false, "cross_layer_sharing": false}, "prompt_length": 32, "batch_size": 1, "seed": 1337, "pretrained": "gpt2-medium", "benchmark_name": "latency_vs_T", "version": "v1", "version_description": "KV-cache enabled", "use_cache": true, "kv_cache_quant": false, "cross_layer_sharing": false, "T": 192, "time_total_ms_median": 615.1321411132812, "time_total_ms_mean": 618.4972534179688, "time_total_ms_std": 8.302702903747559, "time_per_token_ms_median": 3.2038132349650064, "time_per_token_ms_std": 0.04324324429035187, "n_samples": 20, "n_outliers_removed": 0}
{"implementation_name": "baseline", "gpu_name": "NVIDIA RTX A6000", "gpu_total_vram": 51033931776, "python_version": "3.11.14", "pytorch_version": "2.9.1+cu128", "cuda_version": "12.8", "dtype": "bfloat16", "model_config": {"n_layer": 24, "n_head": 16, "n_embd": 1024, "block_size": 1024, "vocab_size": 50257, "dropout": 0.0, "bias": true, "kv_cache_quant": false, "cross_layer_sharing": false}, "prompt_length": 32, "batch_size": 1, "seed": 1337, "pretrained": "gpt2-medium", "benchmark_name": "latency_vs_T", "version": "v1", "version_description": "KV-cache enabled", "use_cache": true, "kv_cache_quant": false, "cross_layer_sharing": false, "T": 224, "time_total_ms_median": 719.3067626953125, "time_total_ms_mean": 720.1832275390625, "time_total_ms_std": 2.324553966522217, "time_per_token_ms_median": 3.2111909048897878, "time_per_token_ms_std": 0.010377473064831324, "n_samples": 18, "n_outliers_removed": 2}
{"implementation_name": "baseline", "gpu_name": "NVIDIA RTX A6000", "gpu_total_vram": 51033931776, "python_version": "3.11.14", "pytorch_version": "2.9.1+cu128", "cuda_version": "12.8", "dtype": "bfloat16", "model_config": {"n_layer": 24, "n_head": 16, "n_embd": 1024, "block_size": 1024, "vocab_size": 50257, "dropout": 0.0, "bias": true, "kv_cache_quant": false, "cross_layer_sharing": false}, "prompt_length": 32, "batch_size": 1, "seed": 1337, "pretrained": "gpt2-medium", "benchmark_name": "latency_vs_T", "version": "v1", "version_description": "KV-cache enabled", "use_cache": true, "kv_cache_quant": false, "cross_layer_sharing": false, "T": 256, "time_total_ms_median": 819.61474609375, "time_total_ms_mean": 820.4910888671875, "time_total_ms_std": 4.1368818283081055, "time_per_token_ms_median": 3.201620101928711, "time_per_token_ms_std": 0.016159694641828537, "n_samples": 20, "n_outliers_removed": 0}
{"implementation_name": "baseline", "gpu_name": "NVIDIA RTX A6000", "gpu_total_vram": 51033931776, "python_version": "3.11.14", "pytorch_version": "2.9.1+cu128", "cuda_version": "12.8", "dtype": "bfloat16", "model_config": {"n_layer": 24, "n_head": 16, "n_embd": 1024, "block_size": 1024, "vocab_size": 50257, "dropout": 0.0, "bias": true, "kv_cache_quant": false, "cross_layer_sharing": false}, "prompt_length": 32, "batch_size": 1, "seed": 1337, "pretrained": "gpt2-medium", "benchmark_name": "latency_vs_T", "version": "v1", "version_description": "KV-cache enabled", "use_cache": true, "kv_cache_quant": false, "cross_layer_sharing": false, "T": 320, "time_total_ms_median": 1039.880126953125, "time_total_ms_mean": 1039.5130615234375, "time_total_ms_std": 4.734413146972656, "time_per_token_ms_median": 3.249625396728516, "time_per_token_ms_std": 0.014795041084289551, "n_samples": 20, "n_outliers_removed": 0}
{"implementation_name": "baseline", "gpu_name": "NVIDIA RTX A6000", "gpu_total_vram": 51033931776, "python_version": "3.11.14", "pytorch_version": "2.9.1+cu128", "cuda_version": "12.8", "dtype": "bfloat16", "model_config": {"n_layer": 24, "n_head": 16, "n_embd": 1024, "block_size": 1024, "vocab_size": 50257, "dropout": 0.0, "bias": true, "kv_cache_quant": false, "cross_layer_sharing": false}, "prompt_length": 32, "batch_size": 1, "seed": 1337, "pretrained": "gpt2-medium", "benchmark_name": "latency_vs_T", "version": "v1", "version_description": "KV-cache enabled", "use_cache": true, "kv_cache_quant": false, "cross_layer_sharing": false, "T": 384, "time_total_ms_median": 1233.943603515625, "time_total_ms_mean": 1235.1087646484375, "time_total_ms_std": 4.278681755065918, "time_per_token_ms_median": 3.21339480082194, "time_per_token_ms_std": 0.011142400403817495, "n_samples": 20, "n_outliers_removed": 0}
{"implementation_name": "baseline", "gpu_name": "NVIDIA RTX A6000", "gpu_total_vram": 51033931776, "python_version": "3.11.14", "pytorch_version": "2.9.1+cu128", "cuda_version": "12.8", "dtype": "bfloat16", "model_config": {"n_layer": 24, "n_head": 16, "n_embd": 1024, "block_size": 1024, "vocab_size": 50257, "dropout": 0.0, "bias": true, "kv_cache_quant": false, "cross_layer_sharing": false}, "prompt_length": 32, "batch_size": 1, "seed": 1337, "pretrained": "gpt2-medium", "benchmark_name": "latency_vs_T", "version": "v1", "version_description": "KV-cache enabled", "use_cache": true, "kv_cache_quant": false, "cross_layer_sharing": false, "T": 448, "time_total_ms_median": 1444.5045166015625, "time_total_ms_mean": 1445.9534912109375, "time_total_ms_std": 7.233297348022461, "time_per_token_ms_median": 3.2243404388427734, "time_per_token_ms_std": 0.01614575300897871, "n_samples": 19, "n_outliers_removed": 1}
{"implementation_name": "baseline", "gpu_name": "NVIDIA RTX A6000", "gpu_total_vram": 51033931776, "python_version": "3.11.14", "pytorch_version": "2.9.1+cu128", "cuda_version": "12.8", "dtype": "bfloat16", "model_config": {"n_layer": 24, "n_head": 16, "n_embd": 1024, "block_size": 1024, "vocab_size": 50257, "dropout": 0.0, "bias": true, "kv_cache_quant": false, "cross_layer_sharing": false}, "prompt_length": 32, "batch_size": 1, "seed": 1337, "pretrained": "gpt2-medium", "benchmark_name": "latency_vs_T", "version": "v1", "version_description": "KV-cache enabled", "use_cache": true, "kv_cache_quant": false, "cross_layer_sharing": false, "T": 512, "time_total_ms_median": 1662.2581787109375, "time_total_ms_mean": 1663.710693359375, "time_total_ms_std": 5.256898880004883, "time_per_token_ms_median": 3.2465980052948, "time_per_token_ms_std": 0.010267380625009537, "n_samples": 20, "n_outliers_removed": 0}
{"implementation_name": "baseline", "gpu_name": "NVIDIA RTX A6000", "gpu_total_vram": 51033931776, "python_version": "3.11.14", "pytorch_version": "2.9.1+cu128", "cuda_version": "12.8", "dtype": "bfloat16", "model_config": {"n_layer": 24, "n_head": 16, "n_embd": 1024, "block_size": 1024, "vocab_size": 50257, "dropout": 0.0, "bias": true, "kv_cache_quant": false, "cross_layer_sharing": false}, "prompt_length": 32, "batch_size": 1, "seed": 1337, "pretrained": "gpt2-medium", "benchmark_name": "latency_vs_T", "version": "v1", "version_description": "KV-cache enabled", "use_cache": true, "kv_cache_quant": false, "cross_layer_sharing": false, "T": 640, "time_total_ms_median": 2082.69921875, "time_total_ms_mean": 2082.6875, "time_total_ms_std": 10.191619873046875, "time_per_token_ms_median": 3.254217529296875, "time_per_token_ms_std": 0.015924406051635743, "n_samples": 19, "n_outliers_removed": 1}
{"implementation_name": "baseline", "gpu_name": "NVIDIA RTX A6000", "gpu_total_vram": 51033931776, "python_version": "3.11.14", "pytorch_version": "2.9.1+cu128", "cuda_version": "12.8", "dtype": "bfloat16", "model_config": {"n_layer": 24, "n_head": 16, "n_embd": 1024, "block_size": 1024, "vocab_size": 50257, "dropout": 0.0, "bias": true, "kv_cache_quant": false, "cross_layer_sharing": false}, "prompt_length": 32, "batch_size": 1, "seed": 1337, "pretrained": "gpt2-medium", "benchmark_name": "latency_vs_T", "version": "v1", "version_description": "KV-cache enabled", "use_cache": true, "kv_cache_quant": false, "cross_layer_sharing": false, "T": 768, "time_total_ms_median": 2508.524658203125, "time_total_ms_mean": 2514.890625, "time_total_ms_std": 16.213335037231445, "time_per_token_ms_median": 3.266308148701986, "time_per_token_ms_std": 0.021111113329728443, "n_samples": 20, "n_outliers_removed": 0}
{"implementation_name": "baseline", "gpu_name": "NVIDIA RTX A6000", "gpu_total_vram": 51033931776, "python_version": "3.11.14", "pytorch_version": "2.9.1+cu128", "cuda_version": "12.8", "dtype": "bfloat16", "model_config": {"n_layer": 24, "n_head": 16, "n_embd": 1024, "block_size": 1024, "vocab_size": 50257, "dropout": 0.0, "bias": true, "kv_cache_quant": false, "cross_layer_sharing": false}, "prompt_length": 32, "batch_size": 1, "seed": 1337, "pretrained": "gpt2-medium", "benchmark_name": "latency_vs_T", "version": "v1", "version_description": "KV-cache enabled", "use_cache": true, "kv_cache_quant": false, "cross_layer_sharing": false, "T": 896, "time_total_ms_median": 2916.727783203125, "time_total_ms_mean": 2921.99755859375, "time_total_ms_std": 15.115248680114746, "time_per_token_ms_median": 3.255276543753488, "time_per_token_ms_std": 0.016869697187628065, "n_samples": 20, "n_outliers_removed": 0}
{"implementation_name": "baseline", "gpu_name": "NVIDIA RTX A6000", "gpu_total_vram": 51033931776, "python_version": "3.11.14", "pytorch_version": "2.9.1+cu128", "cuda_version": "12.8", "dtype": "bfloat16", "model_config": {"n_layer": 24, "n_head": 16, "n_embd": 1024, "block_size": 1024, "vocab_size": 50257, "dropout": 0.0, "bias": true, "kv_cache_quant": false, "cross_layer_sharing": false}, "prompt_length": 32, "batch_size": 1, "seed": 1337, "pretrained": "gpt2-medium", "benchmark_name": "latency_vs_T", "version": "v1", "version_description": "KV-cache enabled", "use_cache": true, "kv_cache_quant": false, "cross_layer_sharing": false, "T": 1024, "time_total_ms_median": 3347.926025390625, "time_total_ms_mean": 3352.387451171875, "time_total_ms_std": 20.544160842895508, "time_per_token_ms_median": 3.2694590091705322, "time_per_token_ms_std": 0.020062657073140144, "n_samples": 20, "n_outliers_removed": 0}
{"implementation_name": "baseline", "gpu_name": "NVIDIA RTX A6000", "gpu_total_vram": 51033931776, "python_version": "3.11.14", "pytorch_version": "2.9.1+cu128", "cuda_version": "12.8", "dtype": "bfloat16", "model_config": {"n_layer": 24, "n_head": 16, "n_embd": 1024, "block_size": 1024, "vocab_size": 50257, "dropout": 0.0, "bias": true, "kv_cache_quant": true, "cross_layer_sharing": false}, "prompt_length": 32, "batch_size": 1, "seed": 1337, "pretrained": "gpt2-medium", "benchmark_name": "latency_vs_T", "version": "v2", "version_description": "KV-cache + INT8 quantization", "use_cache": true, "kv_cache_quant": true, "cross_layer_sharing": false, "T": 32, "time_total_ms_median": 210.14834594726562, "time_total_ms_mean": 210.11367797851562, "time_total_ms_std": 1.404160499572754, "time_per_token_ms_median": 6.567135810852051, "time_per_token_ms_std": 0.04388001561164856, "n_samples": 20, "n_outliers_removed": 0}
{"implementation_name": "baseline", "gpu_name": "NVIDIA RTX A6000", "gpu_total_vram": 51033931776, "python_version": "3.11.14", "pytorch_version": "2.9.1+cu128", "cuda_version": "12.8", "dtype": "bfloat16", "model_config": {"n_layer": 24, "n_head": 16, "n_embd": 1024, "block_size": 1024, "vocab_size": 50257, "dropout": 0.0, "bias": true, "kv_cache_quant": true, "cross_layer_sharing": false}, "prompt_length": 32, "batch_size": 1, "seed": 1337, "pretrained": "gpt2-medium", "benchmark_name": "latency_vs_T", "version": "v2", "version_description": "KV-cache + INT8 quantization", "use_cache": true, "kv_cache_quant": true, "cross_layer_sharing": false, "T": 64, "time_total_ms_median": 414.8019104003906, "time_total_ms_mean": 415.19873046875, "time_total_ms_std": 2.1652185916900635, "time_per_token_ms_median": 6.4812798500061035, "time_per_token_ms_std": 0.03383154049515724, "n_samples": 18, "n_outliers_removed": 2}
{"implementation_name": "baseline", "gpu_name": "NVIDIA RTX A6000", "gpu_total_vram": 51033931776, "python_version": "3.11.14", "pytorch_version": "2.9.1+cu128", "cuda_version": "12.8", "dtype": "bfloat16", "model_config": {"n_layer": 24, "n_head": 16, "n_embd": 1024, "block_size": 1024, "vocab_size": 50257, "dropout": 0.0, "bias": true, "kv_cache_quant": true, "cross_layer_sharing": false}, "prompt_length": 32, "batch_size": 1, "seed": 1337, "pretrained": "gpt2-medium", "benchmark_name": "latency_vs_T", "version": "v2", "version_description": "KV-cache + INT8 quantization", "use_cache": true, "kv_cache_quant": true, "cross_layer_sharing": false, "T": 96, "time_total_ms_median": 625.3997802734375, "time_total_ms_mean": 626.6922607421875, "time_total_ms_std": 5.454653263092041, "time_per_token_ms_median": 6.514581044514974, "time_per_token_ms_std": 0.05681930482387543, "n_samples": 20, "n_outliers_removed": 0}
{"implementation_name": "baseline", "gpu_name": "NVIDIA RTX A6000", "gpu_total_vram": 51033931776, "python_version": "3.11.14", "pytorch_version": "2.9.1+cu128", "cuda_version": "12.8", "dtype": "bfloat16", "model_config": {"n_layer": 24, "n_head": 16, "n_embd": 1024, "block_size": 1024, "vocab_size": 50257, "dropout": 0.0, "bias": true, "kv_cache_quant": true, "cross_layer_sharing": false}, "prompt_length": 32, "batch_size": 1, "seed": 1337, "pretrained": "gpt2-medium", "benchmark_name": "latency_vs_T", "version": "v2", "version_description": "KV-cache + INT8 quantization", "use_cache": true, "kv_cache_quant": true, "cross_layer_sharing": false, "T": 128, "time_total_ms_median": 834.3859252929688, "time_total_ms_mean": 834.4902954101562, "time_total_ms_std": 3.406094789505005, "time_per_token_ms_median": 6.518640041351318, "time_per_token_ms_std": 0.02661011554300785, "n_samples": 18, "n_outliers_removed": 2}
{"implementation_name": "baseline", "gpu_name": "NVIDIA RTX A6000", "gpu_total_vram": 51033931776, "python_version": "3.11.14", "pytorch_version": "2.9.1+cu128", "cuda_version": "12.8", "dtype": "bfloat16", "model_config": {"n_layer": 24, "n_head": 16, "n_embd": 1024, "block_size": 1024, "vocab_size": 50257, "dropout": 0.0, "bias": true, "kv_cache_quant": true, "cross_layer_sharing": false}, "prompt_length": 32, "batch_size": 1, "seed": 1337, "pretrained": "gpt2-medium", "benchmark_name": "latency_vs_T", "version": "v2", "version_description": "KV-cache + INT8 quantization", "use_cache": true, "kv_cache_quant": true, "cross_layer_sharing": false, "T": 160, "time_total_ms_median": 1041.4541015625, "time_total_ms_mean": 1042.7052001953125, "time_total_ms_std": 5.614042282104492, "time_per_token_ms_median": 6.509088134765625, "time_per_token_ms_std": 0.035087764263153076, "n_samples": 20, "n_outliers_removed": 0}
{"implementation_name": "baseline", "gpu_name": "NVIDIA RTX A6000", "gpu_total_vram": 51033931776, "python_version": "3.11.14", "pytorch_version": "2.9.1+cu128", "cuda_version": "12.8", "dtype": "bfloat16", "model_config": {"n_layer": 24, "n_head": 16, "n_embd": 1024, "block_size": 1024, "vocab_size": 50257, "dropout": 0.0, "bias": true, "kv_cache_quant": true, "cross_layer_sharing": false}, "prompt_length": 32, "batch_size": 1, "seed": 1337, "pretrained": "gpt2-medium", "benchmark_name": "latency_vs_T", "version": "v2", "version_description": "KV-cache + INT8 quantization", "use_cache": true, "kv_cache_quant": true, "cross_layer_sharing": false, "T": 192, "time_total_ms_median": 1244.4825439453125, "time_total_ms_mean": 1246.2860107421875, "time_total_ms_std": 6.329777717590332, "time_per_token_ms_median": 6.481679916381836, "time_per_token_ms_std": 0.03296759227911631, "n_samples": 20, "n_outliers_removed": 0}
{"implementation_name": "baseline", "gpu_name": "NVIDIA RTX A6000", "gpu_total_vram": 51033931776, "python_version": "3.11.14", "pytorch_version": "2.9.1+cu128", "cuda_version": "12.8", "dtype": "bfloat16", "model_config": {"n_layer": 24, "n_head": 16, "n_embd": 1024, "block_size": 1024, "vocab_size": 50257, "dropout": 0.0, "bias": true, "kv_cache_quant": true, "cross_layer_sharing": false}, "prompt_length": 32, "batch_size": 1, "seed": 1337, "pretrained": "gpt2-medium", "benchmark_name": "latency_vs_T", "version": "v2", "version_description": "KV-cache + INT8 quantization", "use_cache": true, "kv_cache_quant": true, "cross_layer_sharing": false, "T": 224, "time_total_ms_median": 1450.8175048828125, "time_total_ms_mean": 1452.66064453125, "time_total_ms_std": 7.046294689178467, "time_per_token_ms_median": 6.476863861083984, "time_per_token_ms_std": 0.031456672719546726, "n_samples": 20, "n_outliers_removed": 0}
{"implementation_name": "baseline", "gpu_name": "NVIDIA RTX A6000", "gpu_total_vram": 51033931776, "python_version": "3.11.14", "pytorch_version": "2.9.1+cu128", "cuda_version": "12.8", "dtype": "bfloat16", "model_config": {"n_layer": 24, "n_head": 16, "n_embd": 1024, "block_size": 1024, "vocab_size": 50257, "dropout": 0.0, "bias": true, "kv_cache_quant": true, "cross_layer_sharing": false}, "prompt_length": 32, "batch_size": 1, "seed": 1337, "pretrained": "gpt2-medium", "benchmark_name": "latency_vs_T", "version": "v2", "version_description": "KV-cache + INT8 quantization", "use_cache": true, "kv_cache_quant": true, "cross_layer_sharing": false, "T": 256, "time_total_ms_median": 1659.46875, "time_total_ms_mean": 1662.218017578125, "time_total_ms_std": 9.2792329788208, "time_per_token_ms_median": 6.4822998046875, "time_per_token_ms_std": 0.03624700382351875, "n_samples": 20, "n_outliers_removed": 0}
{"implementation_name": "baseline", "gpu_name": "NVIDIA RTX A6000", "gpu_total_vram": 51033931776, "python_version": "3.11.14", "pytorch_version": "2.9.1+cu128", "cuda_version": "12.8", "dtype": "bfloat16", "model_config": {"n_layer": 24, "n_head": 16, "n_embd": 1024, "block_size": 1024, "vocab_size": 50257, "dropout": 0.0, "bias": true, "kv_cache_quant": true, "cross_layer_sharing": false}, "prompt_length": 32, "batch_size": 1, "seed": 1337, "pretrained": "gpt2-medium", "benchmark_name": "latency_vs_T", "version": "v2", "version_description": "KV-cache + INT8 quantization", "use_cache": true, "kv_cache_quant": true, "cross_layer_sharing": false, "T": 320, "time_total_ms_median": 2081.8740234375, "time_total_ms_mean": 2084.213623046875, "time_total_ms_std": 9.930800437927246, "time_per_token_ms_median": 6.505856323242187, "time_per_token_ms_std": 0.031033751368522645, "n_samples": 20, "n_outliers_removed": 0}
{"implementation_name": "baseline", "gpu_name": "NVIDIA RTX A6000", "gpu_total_vram": 51033931776, "python_version": "3.11.14", "pytorch_version": "2.9.1+cu128", "cuda_version": "12.8", "dtype": "bfloat16", "model_config": {"n_layer": 24, "n_head": 16, "n_embd": 1024, "block_size": 1024, "vocab_size": 50257, "dropout": 0.0, "bias": true, "kv_cache_quant": true, "cross_layer_sharing": false}, "prompt_length": 32, "batch_size": 1, "seed": 1337, "pretrained": "gpt2-medium", "benchmark_name": "latency_vs_T", "version": "v2", "version_description": "KV-cache + INT8 quantization", "use_cache": true, "kv_cache_quant": true, "cross_layer_sharing": false, "T": 384, "time_total_ms_median": 2516.799560546875, "time_total_ms_mean": 2518.77197265625, "time_total_ms_std": 12.15829086303711, "time_per_token_ms_median": 6.554165522257487, "time_per_token_ms_std": 0.03166221578915914, "n_samples": 20, "n_outliers_removed": 0}
{"implementation_name": "baseline", "gpu_name": "NVIDIA RTX A6000", "gpu_total_vram": 51033931776, "python_version": "3.11.14", "pytorch_version": "2.9.1+cu128", "cuda_version": "12.8", "dtype": "bfloat16", "model_config": {"n_layer": 24, "n_head": 16, "n_embd": 1024, "block_size": 1024, "vocab_size": 50257, "dropout": 0.0, "bias": true, "kv_cache_quant": true, "cross_layer_sharing": false}, "prompt_length": 32, "batch_size": 1, "seed": 1337, "pretrained": "gpt2-medium", "benchmark_name": "latency_vs_T", "version": "v2", "version_description": "KV-cache + INT8 quantization", "use_cache": true, "kv_cache_quant": true, "cross_layer_sharing": false, "T": 448, "time_total_ms_median": 2947.758056640625, "time_total_ms_mean": 2945.52294921875, "time_total_ms_std": 14.651957511901855, "time_per_token_ms_median": 6.5798170907156805, "time_per_token_ms_std": 0.032705262303352356, "n_samples": 20, "n_outliers_removed": 0}
{"implementation_name": "baseline", "gpu_name": "NVIDIA RTX A6000", "gpu_total_vram": 51033931776, "python_version": "3.11.14", "pytorch_version": "2.9.1+cu128", "cuda_version": "12.8", "dtype": "bfloat16", "model_config": {"n_layer": 24, "n_head": 16, "n_embd": 1024, "block_size": 1024, "vocab_size": 50257, "dropout": 0.0, "bias": true, "kv_cache_quant": true, "cross_layer_sharing": false}, "prompt_length": 32, "batch_size": 1, "seed": 1337, "pretrained": "gpt2-medium", "benchmark_name": "latency_vs_T", "version": "v2", "version_description": "KV-cache + INT8 quantization", "use_cache": true, "kv_cache_quant": true, "cross_layer_sharing": false, "T": 512, "time_total_ms_median": 3364.87109375, "time_total_ms_mean": 3369.557861328125, "time_total_ms_std": 18.462427139282227, "time_per_token_ms_median": 6.572013854980469, "time_per_token_ms_std": 0.0360594280064106, "n_samples": 20, "n_outliers_removed": 0}
{"implementation_name": "baseline", "gpu_name": "NVIDIA RTX A6000", "gpu_total_vram": 51033931776, "python_version": "3.11.14", "pytorch_version": "2.9.1+cu128", "cuda_version": "12.8", "dtype": "bfloat16", "model_config": {"n_layer": 24, "n_head": 16, "n_embd": 1024, "block_size": 1024, "vocab_size": 50257, "dropout": 0.0, "bias": true, "kv_cache_quant": true, "cross_layer_sharing": false}, "prompt_length": 32, "batch_size": 1, "seed": 1337, "pretrained": "gpt2-medium", "benchmark_name": "latency_vs_T", "version": "v2", "version_description": "KV-cache + INT8 quantization", "use_cache": true, "kv_cache_quant": true, "cross_layer_sharing": false, "T": 640, "time_total_ms_median": 4199.04931640625, "time_total_ms_mean": 4203.1005859375, "time_total_ms_std": 23.791584014892578, "time_per_token_ms_median": 6.561014556884766, "time_per_token_ms_std": 0.03717435002326965, "n_samples": 20, "n_outliers_removed": 0}
{"implementation_name": "baseline", "gpu_name": "NVIDIA RTX A6000", "gpu_total_vram": 51033931776, "python_version": "3.11.14", "pytorch_version": "2.9.1+cu128", "cuda_version": "12.8", "dtype": "bfloat16", "model_config": {"n_layer": 24, "n_head": 16, "n_embd": 1024, "block_size": 1024, "vocab_size": 50257, "dropout": 0.0, "bias": true, "kv_cache_quant": true, "cross_layer_sharing": false}, "prompt_length": 32, "batch_size": 1, "seed": 1337, "pretrained": "gpt2-medium", "benchmark_name": "latency_vs_T", "version": "v2", "version_description": "KV-cache + INT8 quantization", "use_cache": true, "kv_cache_quant": true, "cross_layer_sharing": false, "T": 768, "time_total_ms_median": 5043.4755859375, "time_total_ms_mean": 5045.1015625, "time_total_ms_std": 16.24015235900879, "time_per_token_ms_median": 6.567025502522786, "time_per_token_ms_std": 0.021146031717459362, "n_samples": 20, "n_outliers_removed": 0}
{"implementation_name": "baseline", "gpu_name": "NVIDIA RTX A6000", "gpu_total_vram": 51033931776, "python_version": "3.11.14", "pytorch_version": "2.9.1+cu128", "cuda_version": "12.8", "dtype": "bfloat16", "model_config": {"n_layer": 24, "n_head": 16, "n_embd": 1024, "block_size": 1024, "vocab_size": 50257, "dropout": 0.0, "bias": true, "kv_cache_quant": true, "cross_layer_sharing": false}, "prompt_length": 32, "batch_size": 1, "seed": 1337, "pretrained": "gpt2-medium", "benchmark_name": "latency_vs_T", "version": "v2", "version_description": "KV-cache + INT8 quantization", "use_cache": true, "kv_cache_quant": true, "cross_layer_sharing": false, "T": 896, "time_total_ms_median": 5876.365234375, "time_total_ms_mean": 5884.1669921875, "time_total_ms_std": 25.144229888916016, "time_per_token_ms_median": 6.558443341936384, "time_per_token_ms_std": 0.02806275657245091, "n_samples": 20, "n_outliers_removed": 0}
{"implementation_name": "baseline", "gpu_name": "NVIDIA RTX A6000", "gpu_total_vram": 51033931776, "python_version": "3.11.14", "pytorch_version": "2.9.1+cu128", "cuda_version": "12.8", "dtype": "bfloat16", "model_config": {"n_layer": 24, "n_head": 16, "n_embd": 1024, "block_size": 1024, "vocab_size": 50257, "dropout": 0.0, "bias": true, "kv_cache_quant": true, "cross_layer_sharing": false}, "prompt_length": 32, "batch_size": 1, "seed": 1337, "pretrained": "gpt2-medium", "benchmark_name": "latency_vs_T", "version": "v2", "version_description": "KV-cache + INT8 quantization", "use_cache": true, "kv_cache_quant": true, "cross_layer_sharing": false, "T": 1024, "time_total_ms_median": 6754.0625, "time_total_ms_mean": 6765.10546875, "time_total_ms_std": 46.713897705078125, "time_per_token_ms_median": 6.59576416015625, "time_per_token_ms_std": 0.045619040727615356, "n_samples": 20, "n_outliers_removed": 0}
{"implementation_name": "baseline", "gpu_name": "NVIDIA RTX A6000", "gpu_total_vram": 51033931776, "python_version": "3.11.14", "pytorch_version": "2.9.1+cu128", "cuda_version": "12.8", "dtype": "bfloat16", "model_config": {"n_layer": 24, "n_head": 16, "n_embd": 1024, "block_size": 1024, "vocab_size": 50257, "dropout": 0.0, "bias": true, "kv_cache_quant": false, "cross_layer_sharing": true}, "prompt_length": 32, "batch_size": 1, "seed": 1337, "pretrained": "gpt2-medium", "benchmark_name": "latency_vs_T", "version": "v3", "version_description": "KV-cache + cross-layer sharing", "use_cache": true, "kv_cache_quant": false, "cross_layer_sharing": true, "T": 32, "time_total_ms_median": 94.12095642089844, "time_total_ms_mean": 94.06033325195312, "time_total_ms_std": 0.5857535600662231, "time_per_token_ms_median": 2.941279888153076, "time_per_token_ms_std": 0.018304798752069473, "n_samples": 17, "n_outliers_removed": 3}
{"implementation_name": "baseline", "gpu_name": "NVIDIA RTX A6000", "gpu_total_vram": 51033931776, "python_version": "3.11.14", "pytorch_version": "2.9.1+cu128", "cuda_version": "12.8", "dtype": "bfloat16", "model_config": {"n_layer": 24, "n_head": 16, "n_embd": 1024, "block_size": 1024, "vocab_size": 50257, "dropout": 0.0, "bias": true, "kv_cache_quant": false, "cross_layer_sharing": true}, "prompt_length": 32, "batch_size": 1, "seed": 1337, "pretrained": "gpt2-medium", "benchmark_name": "latency_vs_T", "version": "v3", "version_description": "KV-cache + cross-layer sharing", "use_cache": true, "kv_cache_quant": false, "cross_layer_sharing": true, "T": 64, "time_total_ms_median": 187.85792541503906, "time_total_ms_mean": 188.18222045898438, "time_total_ms_std": 1.6622670888900757, "time_per_token_ms_median": 2.9352800846099854, "time_per_token_ms_std": 0.025972923263907433, "n_samples": 20, "n_outliers_removed": 0}
{"implementation_name": "baseline", "gpu_name": "NVIDIA RTX A6000", "gpu_total_vram": 51033931776, "python_version": "3.11.14", "pytorch_version": "2.9.1+cu128", "cuda_version": "12.8", "dtype": "bfloat16", "model_config": {"n_layer": 24, "n_head": 16, "n_embd": 1024, "block_size": 1024, "vocab_size": 50257, "dropout": 0.0, "bias": true, "kv_cache_quant": false, "cross_layer_sharing": true}, "prompt_length": 32, "batch_size": 1, "seed": 1337, "pretrained": "gpt2-medium", "benchmark_name": "latency_vs_T", "version": "v3", "version_description": "KV-cache + cross-layer sharing", "use_cache": true, "kv_cache_quant": false, "cross_layer_sharing": true, "T": 96, "time_total_ms_median": 283.5435485839844, "time_total_ms_mean": 284.2601013183594, "time_total_ms_std": 2.3281774520874023, "time_per_token_ms_median": 2.9535786310831704, "time_per_token_ms_std": 0.024251848459243774, "n_samples": 20, "n_outliers_removed": 0}
{"implementation_name": "baseline", "gpu_name": "NVIDIA RTX A6000", "gpu_total_vram": 51033931776, "python_version": "3.11.14", "pytorch_version": "2.9.1+cu128", "cuda_version": "12.8", "dtype": "bfloat16", "model_config": {"n_layer": 24, "n_head": 16, "n_embd": 1024, "block_size": 1024, "vocab_size": 50257, "dropout": 0.0, "bias": true, "kv_cache_quant": false, "cross_layer_sharing": true}, "prompt_length": 32, "batch_size": 1, "seed": 1337, "pretrained": "gpt2-medium", "benchmark_name": "latency_vs_T", "version": "v3", "version_description": "KV-cache + cross-layer sharing", "use_cache": true, "kv_cache_quant": false, "cross_layer_sharing": true, "T": 128, "time_total_ms_median": 378.5041809082031, "time_total_ms_mean": 379.0414123535156, "time_total_ms_std": 2.3635120391845703, "time_per_token_ms_median": 2.957063913345337, "time_per_token_ms_std": 0.018464937806129456, "n_samples": 18, "n_outliers_removed": 2}
{"implementation_name": "baseline", "gpu_name": "NVIDIA RTX A6000", "gpu_total_vram": 51033931776, "python_version": "3.11.14", "pytorch_version": "2.9.1+cu128", "cuda_version": "12.8", "dtype": "bfloat16", "model_config": {"n_layer": 24, "n_head": 16, "n_embd": 1024, "block_size": 1024, "vocab_size": 50257, "dropout": 0.0, "bias": true, "kv_cache_quant": false, "cross_layer_sharing": true}, "prompt_length": 32, "batch_size": 1, "seed": 1337, "pretrained": "gpt2-medium", "benchmark_name": "latency_vs_T", "version": "v3", "version_description": "KV-cache + cross-layer sharing", "use_cache": true, "kv_cache_quant": false, "cross_layer_sharing": true, "T": 160, "time_total_ms_median": 471.564208984375, "time_total_ms_mean": 471.9737548828125, "time_total_ms_std": 2.008064031600952, "time_per_token_ms_median": 2.947276306152344, "time_per_token_ms_std": 0.01255040019750595, "n_samples": 18, "n_outliers_removed": 2}
{"implementation_name": "baseline", "gpu_name": "NVIDIA RTX A6000", "gpu_total_vram": 51033931776, "python_version": "3.11.14", "pytorch_version": "2.9.1+cu128", "cuda_version": "12.8", "dtype": "bfloat16", "model_config": {"n_layer": 24, "n_head": 16, "n_embd": 1024, "block_size": 1024, "vocab_size": 50257, "dropout": 0.0, "bias": true, "kv_cache_quant": false, "cross_layer_sharing": true}, "prompt_length": 32, "batch_size": 1, "seed": 1337, "pretrained": "gpt2-medium", "benchmark_name": "latency_vs_T", "version": "v3", "version_description": "KV-cache + cross-layer sharing", "use_cache": true, "kv_cache_quant": false, "cross_layer_sharing": true, "T": 192, "time_total_ms_median": 568.7427368164062, "time_total_ms_mean": 568.7244262695312, "time_total_ms_std": 2.2960193157196045, "time_per_token_ms_median": 2.9622017542521157, "time_per_token_ms_std": 0.011958433936039606, "n_samples": 19, "n_outliers_removed": 1}
{"implementation_name": "baseline", "gpu_name": "NVIDIA RTX A6000", "gpu_total_vram": 51033931776, "python_version": "3.11.14", "pytorch_version": "2.9.1+cu128", "cuda_version": "12.8", "dtype": "bfloat16", "model_config": {"n_layer": 24, "n_head": 16, "n_embd": 1024, "block_size": 1024, "vocab_size": 50257, "dropout": 0.0, "bias": true, "kv_cache_quant": false, "cross_layer_sharing": true}, "prompt_length": 32, "batch_size": 1, "seed": 1337, "pretrained": "gpt2-medium", "benchmark_name": "latency_vs_T", "version": "v3", "version_description": "KV-cache + cross-layer sharing", "use_cache": true, "kv_cache_quant": false, "cross_layer_sharing": true, "T": 224, "time_total_ms_median": 660.8414916992188, "time_total_ms_mean": 661.6649169921875, "time_total_ms_std": 4.615694999694824, "time_per_token_ms_median": 2.9501852308000838, "time_per_token_ms_std": 0.020605781248637607, "n_samples": 19, "n_outliers_removed": 1}
{"implementation_name": "baseline", "gpu_name": "NVIDIA RTX A6000", "gpu_total_vram": 51033931776, "python_version": "3.11.14", "pytorch_version": "2.9.1+cu128", "cuda_version": "12.8", "dtype": "bfloat16", "model_config": {"n_layer": 24, "n_head": 16, "n_embd": 1024, "block_size": 1024, "vocab_size": 50257, "dropout": 0.0, "bias": true, "kv_cache_quant": false, "cross_layer_sharing": true}, "prompt_length": 32, "batch_size": 1, "seed": 1337, "pretrained": "gpt2-medium", "benchmark_name": "latency_vs_T", "version": "v3", "version_description": "KV-cache + cross-layer sharing", "use_cache": true, "kv_cache_quant": false, "cross_layer_sharing": true, "T": 256, "time_total_ms_median": 763.6060180664062, "time_total_ms_mean": 762.5828857421875, "time_total_ms_std": 6.79620361328125, "time_per_token_ms_median": 2.9828360080718994, "time_per_token_ms_std": 0.026547670364379883, "n_samples": 19, "n_outliers_removed": 1}
{"implementation_name": "baseline", "gpu_name": "NVIDIA RTX A6000", "gpu_total_vram": 51033931776, "python_version": "3.11.14", "pytorch_version": "2.9.1+cu128", "cuda_version": "12.8", "dtype": "bfloat16", "model_config": {"n_layer": 24, "n_head": 16, "n_embd": 1024, "block_size": 1024, "vocab_size": 50257, "dropout": 0.0, "bias": true, "kv_cache_quant": false, "cross_layer_sharing": true}, "prompt_length": 32, "batch_size": 1, "seed": 1337, "pretrained": "gpt2-medium", "benchmark_name": "latency_vs_T", "version": "v3", "version_description": "KV-cache + cross-layer sharing", "use_cache": true, "kv_cache_quant": false, "cross_layer_sharing": true, "T": 320, "time_total_ms_median": 958.396240234375, "time_total_ms_mean": 961.0968017578125, "time_total_ms_std": 7.0211052894592285, "time_per_token_ms_median": 2.9949882507324217, "time_per_token_ms_std": 0.02194095402956009, "n_samples": 20, "n_outliers_removed": 0}
{"implementation_name": "baseline", "gpu_name": "NVIDIA RTX A6000", "gpu_total_vram": 51033931776, "python_version": "3.11.14", "pytorch_version": "2.9.1+cu128", "cuda_version": "12.8", "dtype": "bfloat16", "model_config": {"n_layer": 24, "n_head": 16, "n_embd": 1024, "block_size": 1024, "vocab_size": 50257, "dropout": 0.0, "bias": true, "kv_cache_quant": false, "cross_layer_sharing": true}, "prompt_length": 32, "batch_size": 1, "seed": 1337, "pretrained": "gpt2-medium", "benchmark_name": "latency_vs_T", "version": "v3", "version_description": "KV-cache + cross-layer sharing", "use_cache": true, "kv_cache_quant": false, "cross_layer_sharing": true, "T": 384, "time_total_ms_median": 1164.6800537109375, "time_total_ms_mean": 1165.438232421875, "time_total_ms_std": 4.7037153244018555, "time_per_token_ms_median": 3.0330209732055664, "time_per_token_ms_std": 0.0122492586572965, "n_samples": 18, "n_outliers_removed": 2}
{"implementation_name": "baseline", "gpu_name": "NVIDIA RTX A6000", "gpu_total_vram": 51033931776, "python_version": "3.11.14", "pytorch_version": "2.9.1+cu128", "cuda_version": "12.8", "dtype": "bfloat16", "model_config": {"n_layer": 24, "n_head": 16, "n_embd": 1024, "block_size": 1024, "vocab_size": 50257, "dropout": 0.0, "bias": true, "kv_cache_quant": false, "cross_layer_sharing": true}, "prompt_length": 32, "batch_size": 1, "seed": 1337, "pretrained": "gpt2-medium", "benchmark_name": "latency_vs_T", "version": "v3", "version_description": "KV-cache + cross-layer sharing", "use_cache": true, "kv_cache_quant": false, "cross_layer_sharing": true, "T": 448, "time_total_ms_median": 1348.7431640625, "time_total_ms_mean": 1348.0313720703125, "time_total_ms_std": 4.064261436462402, "time_per_token_ms_median": 3.010587419782366, "time_per_token_ms_std": 0.009072012134960719, "n_samples": 19, "n_outliers_removed": 1}
{"implementation_name": "baseline", "gpu_name": "NVIDIA RTX A6000", "gpu_total_vram": 51033931776, "python_version": "3.11.14", "pytorch_version": "2.9.1+cu128", "cuda_version": "12.8", "dtype": "bfloat16", "model_config": {"n_layer": 24, "n_head": 16, "n_embd": 1024, "block_size": 1024, "vocab_size": 50257, "dropout": 0.0, "bias": true, "kv_cache_quant": false, "cross_layer_sharing": true}, "prompt_length": 32, "batch_size": 1, "seed": 1337, "pretrained": "gpt2-medium", "benchmark_name": "latency_vs_T", "version": "v3", "version_description": "KV-cache + cross-layer sharing", "use_cache": true, "kv_cache_quant": false, "cross_layer_sharing": true, "T": 512, "time_total_ms_median": 1539.7437744140625, "time_total_ms_mean": 1541.571533203125, "time_total_ms_std": 8.581246376037598, "time_per_token_ms_median": 3.007312059402466, "time_per_token_ms_std": 0.016760246828198433, "n_samples": 19, "n_outliers_removed": 1}
{"implementation_name": "baseline", "gpu_name": "NVIDIA RTX A6000", "gpu_total_vram": 51033931776, "python_version": "3.11.14", "pytorch_version": "2.9.1+cu128", "cuda_version": "12.8", "dtype": "bfloat16", "model_config": {"n_layer": 24, "n_head": 16, "n_embd": 1024, "block_size": 1024, "vocab_size": 50257, "dropout": 0.0, "bias": true, "kv_cache_quant": false, "cross_layer_sharing": true}, "prompt_length": 32, "batch_size": 1, "seed": 1337, "pretrained": "gpt2-medium", "benchmark_name": "latency_vs_T", "version": "v3", "version_description": "KV-cache + cross-layer sharing", "use_cache": true, "kv_cache_quant": false, "cross_layer_sharing": true, "T": 640, "time_total_ms_median": 1942.9560546875, "time_total_ms_mean": 1942.1063232421875, "time_total_ms_std": 9.158879280090332, "time_per_token_ms_median": 3.035868835449219, "time_per_token_ms_std": 0.014310748875141143, "n_samples": 18, "n_outliers_removed": 2}
{"implementation_name": "baseline", "gpu_name": "NVIDIA RTX A6000", "gpu_total_vram": 51033931776, "python_version": "3.11.14", "pytorch_version": "2.9.1+cu128", "cuda_version": "12.8", "dtype": "bfloat16", "model_config": {"n_layer": 24, "n_head": 16, "n_embd": 1024, "block_size": 1024, "vocab_size": 50257, "dropout": 0.0, "bias": true, "kv_cache_quant": false, "cross_layer_sharing": true}, "prompt_length": 32, "batch_size": 1, "seed": 1337, "pretrained": "gpt2-medium", "benchmark_name": "latency_vs_T", "version": "v3", "version_description": "KV-cache + cross-layer sharing", "use_cache": true, "kv_cache_quant": false, "cross_layer_sharing": true, "T": 768, "time_total_ms_median": 2335.429443359375, "time_total_ms_mean": 2334.81201171875, "time_total_ms_std": 12.041135787963867, "time_per_token_ms_median": 3.040923754374186, "time_per_token_ms_std": 0.015678562223911285, "n_samples": 20, "n_outliers_removed": 0}
{"implementation_name": "baseline", "gpu_name": "NVIDIA RTX A6000", "gpu_total_vram": 51033931776, "python_version": "3.11.14", "pytorch_version": "2.9.1+cu128", "cuda_version": "12.8", "dtype": "bfloat16", "model_config": {"n_layer": 24, "n_head": 16, "n_embd": 1024, "block_size": 1024, "vocab_size": 50257, "dropout": 0.0, "bias": true, "kv_cache_quant": false, "cross_layer_sharing": true}, "prompt_length": 32, "batch_size": 1, "seed": 1337, "pretrained": "gpt2-medium", "benchmark_name": "latency_vs_T", "version": "v3", "version_description": "KV-cache + cross-layer sharing", "use_cache": true, "kv_cache_quant": false, "cross_layer_sharing": true, "T": 896, "time_total_ms_median": 2710.04052734375, "time_total_ms_mean": 2715.513671875, "time_total_ms_std": 13.36265754699707, "time_per_token_ms_median": 3.0245988028390065, "time_per_token_ms_std": 0.014913680297987801, "n_samples": 20, "n_outliers_removed": 0}
{"implementation_name": "baseline", "gpu_name": "NVIDIA RTX A6000", "gpu_total_vram": 51033931776, "python_version": "3.11.14", "pytorch_version": "2.9.1+cu128", "cuda_version": "12.8", "dtype": "bfloat16", "model_config": {"n_layer": 24, "n_head": 16, "n_embd": 1024, "block_size": 1024, "vocab_size": 50257, "dropout": 0.0, "bias": true, "kv_cache_quant": false, "cross_layer_sharing": true}, "prompt_length": 32, "batch_size": 1, "seed": 1337, "pretrained": "gpt2-medium", "benchmark_name": "latency_vs_T", "version": "v3", "version_description": "KV-cache + cross-layer sharing", "use_cache": true, "kv_cache_quant": false, "cross_layer_sharing": true, "T": 1024, "time_total_ms_median": 3099.401123046875, "time_total_ms_mean": 3105.39208984375, "time_total_ms_std": 17.739599227905273, "time_per_token_ms_median": 3.026758909225464, "time_per_token_ms_std": 0.017323827371001244, "n_samples": 20, "n_outliers_removed": 0}
{"implementation_name": "baseline", "gpu_name": "NVIDIA RTX A6000", "gpu_total_vram": 51033931776, "python_version": "3.11.14", "pytorch_version": "2.9.1+cu128", "cuda_version": "12.8", "dtype": "bfloat16", "model_config": {"n_layer": 24, "n_head": 16, "n_embd": 1024, "block_size": 1024, "vocab_size": 50257, "dropout": 0.0, "bias": true, "kv_cache_quant": true, "cross_layer_sharing": true}, "prompt_length": 32, "batch_size": 1, "seed": 1337, "pretrained": "gpt2-medium", "benchmark_name": "latency_vs_T", "version": "v4", "version_description": "KV-cache + INT8 + cross-layer sharing", "use_cache": true, "kv_cache_quant": true, "cross_layer_sharing": true, "T": 32, "time_total_ms_median": 164.81280517578125, "time_total_ms_mean": 164.8018798828125, "time_total_ms_std": 1.09382164478302, "time_per_token_ms_median": 5.150400161743164, "time_per_token_ms_std": 0.034181926399469376, "n_samples": 19, "n_outliers_removed": 1}
{"implementation_name": "baseline", "gpu_name": "NVIDIA RTX A6000", "gpu_total_vram": 51033931776, "python_version": "3.11.14", "pytorch_version": "2.9.1+cu128", "cuda_version": "12.8", "dtype": "bfloat16", "model_config": {"n_layer": 24, "n_head": 16, "n_embd": 1024, "block_size": 1024, "vocab_size": 50257, "dropout": 0.0, "bias": true, "kv_cache_quant": true, "cross_layer_sharing": true}, "prompt_length": 32, "batch_size": 1, "seed": 1337, "pretrained": "gpt2-medium", "benchmark_name": "latency_vs_T", "version": "v4", "version_description": "KV-cache + INT8 + cross-layer sharing", "use_cache": true, "kv_cache_quant": true, "cross_layer_sharing": true, "T": 64, "time_total_ms_median": 324.62225341796875, "time_total_ms_mean": 325.1060485839844, "time_total_ms_std": 2.2691547870635986, "time_per_token_ms_median": 5.072222709655762, "time_per_token_ms_std": 0.03545554354786873, "n_samples": 20, "n_outliers_removed": 0}
{"implementation_name": "baseline", "gpu_name": "NVIDIA RTX A6000", "gpu_total_vram": 51033931776, "python_version": "3.11.14", "pytorch_version": "2.9.1+cu128", "cuda_version": "12.8", "dtype": "bfloat16", "model_config": {"n_layer": 24, "n_head": 16, "n_embd": 1024, "block_size": 1024, "vocab_size": 50257, "dropout": 0.0, "bias": true, "kv_cache_quant": true, "cross_layer_sharing": true}, "prompt_length": 32, "batch_size": 1, "seed": 1337, "pretrained": "gpt2-medium", "benchmark_name": "latency_vs_T", "version": "v4", "version_description": "KV-cache + INT8 + cross-layer sharing", "use_cache": true, "kv_cache_quant": true, "cross_layer_sharing": true, "T": 96, "time_total_ms_median": 485.9679260253906, "time_total_ms_mean": 487.0066833496094, "time_total_ms_std": 2.545755386352539, "time_per_token_ms_median": 5.062165896097819, "time_per_token_ms_std": 0.026518285274505615, "n_samples": 20, "n_outliers_removed": 0}
{"implementation_name": "baseline", "gpu_name": "NVIDIA RTX A6000", "gpu_total_vram": 51033931776, "python_version": "3.11.14", "pytorch_version": "2.9.1+cu128", "cuda_version": "12.8", "dtype": "bfloat16", "model_config": {"n_layer": 24, "n_head": 16, "n_embd": 1024, "block_size": 1024, "vocab_size": 50257, "dropout": 0.0, "bias": true, "kv_cache_quant": true, "cross_layer_sharing": true}, "prompt_length": 32, "batch_size": 1, "seed": 1337, "pretrained": "gpt2-medium", "benchmark_name": "latency_vs_T", "version": "v4", "version_description": "KV-cache + INT8 + cross-layer sharing", "use_cache": true, "kv_cache_quant": true, "cross_layer_sharing": true, "T": 128, "time_total_ms_median": 649.955322265625, "time_total_ms_mean": 650.6981201171875, "time_total_ms_std": 3.1115472316741943, "time_per_token_ms_median": 5.077775955200195, "time_per_token_ms_std": 0.024308962747454643, "n_samples": 20, "n_outliers_removed": 0}
{"implementation_name": "baseline", "gpu_name": "NVIDIA RTX A6000", "gpu_total_vram": 51033931776, "python_version": "3.11.14", "pytorch_version": "2.9.1+cu128", "cuda_version": "12.8", "dtype": "bfloat16", "model_config": {"n_layer": 24, "n_head": 16, "n_embd": 1024, "block_size": 1024, "vocab_size": 50257, "dropout": 0.0, "bias": true, "kv_cache_quant": true, "cross_layer_sharing": true}, "prompt_length": 32, "batch_size": 1, "seed": 1337, "pretrained": "gpt2-medium", "benchmark_name": "latency_vs_T", "version": "v4", "version_description": "KV-cache + INT8 + cross-layer sharing", "use_cache": true, "kv_cache_quant": true, "cross_layer_sharing": true, "T": 160, "time_total_ms_median": 810.6731567382812, "time_total_ms_mean": 809.7741088867188, "time_total_ms_std": 3.968881845474243, "time_per_token_ms_median": 5.0667072296142575, "time_per_token_ms_std": 0.02480551153421402, "n_samples": 20, "n_outliers_removed": 0}
{"implementation_name": "baseline", "gpu_name": "NVIDIA RTX A6000", "gpu_total_vram": 51033931776, "python_version": "3.11.14", "pytorch_version": "2.9.1+cu128", "cuda_version": "12.8", "dtype": "bfloat16", "model_config": {"n_layer": 24, "n_head": 16, "n_embd": 1024, "block_size": 1024, "vocab_size": 50257, "dropout": 0.0, "bias": true, "kv_cache_quant": true, "cross_layer_sharing": true}, "prompt_length": 32, "batch_size": 1, "seed": 1337, "pretrained": "gpt2-medium", "benchmark_name": "latency_vs_T", "version": "v4", "version_description": "KV-cache + INT8 + cross-layer sharing", "use_cache": true, "kv_cache_quant": true, "cross_layer_sharing": true, "T": 192, "time_total_ms_median": 967.4383544921875, "time_total_ms_mean": 967.8751220703125, "time_total_ms_std": 2.9624736309051514, "time_per_token_ms_median": 5.03874142964681, "time_per_token_ms_std": 0.01542955016096433, "n_samples": 19, "n_outliers_removed": 1}
{"implementation_name": "baseline", "gpu_name": "NVIDIA RTX A6000", "gpu_total_vram": 51033931776, "python_version": "3.11.14", "pytorch_version": "2.9.1+cu128", "cuda_version": "12.8", "dtype": "bfloat16", "model_config": {"n_layer": 24, "n_head": 16, "n_embd": 1024, "block_size": 1024, "vocab_size": 50257, "dropout": 0.0, "bias": true, "kv_cache_quant": true, "cross_layer_sharing": true}, "prompt_length": 32, "batch_size": 1, "seed": 1337, "pretrained": "gpt2-medium", "benchmark_name": "latency_vs_T", "version": "v4", "version_description": "KV-cache + INT8 + cross-layer sharing", "use_cache": true, "kv_cache_quant": true, "cross_layer_sharing": true, "T": 224, "time_total_ms_median": 1149.7093505859375, "time_total_ms_mean": 1150.1051025390625, "time_total_ms_std": 2.7084927558898926, "time_per_token_ms_median": 5.132631029401507, "time_per_token_ms_std": 0.012091485517365592, "n_samples": 18, "n_outliers_removed": 2}
{"implementation_name": "baseline", "gpu_name": "NVIDIA RTX A6000", "gpu_total_vram": 51033931776, "python_version": "3.11.14", "pytorch_version": "2.9.1+cu128", "cuda_version": "12.8", "dtype": "bfloat16", "model_config": {"n_layer": 24, "n_head": 16, "n_embd": 1024, "block_size": 1024, "vocab_size": 50257, "dropout": 0.0, "bias": true, "kv_cache_quant": true, "cross_layer_sharing": true}, "prompt_length": 32, "batch_size": 1, "seed": 1337, "pretrained": "gpt2-medium", "benchmark_name": "latency_vs_T", "version": "v4", "version_description": "KV-cache + INT8 + cross-layer sharing", "use_cache": true, "kv_cache_quant": true, "cross_layer_sharing": true, "T": 256, "time_total_ms_median": 1295.794189453125, "time_total_ms_mean": 1296.71044921875, "time_total_ms_std": 3.5646119117736816, "time_per_token_ms_median": 5.0616960525512695, "time_per_token_ms_std": 0.013924265280365944, "n_samples": 19, "n_outliers_removed": 1}
{"implementation_name": "baseline", "gpu_name": "NVIDIA RTX A6000", "gpu_total_vram": 51033931776, "python_version": "3.11.14", "pytorch_version": "2.9.1+cu128", "cuda_version": "12.8", "dtype": "bfloat16", "model_config": {"n_layer": 24, "n_head": 16, "n_embd": 1024, "block_size": 1024, "vocab_size": 50257, "dropout": 0.0, "bias": true, "kv_cache_quant": true, "cross_layer_sharing": true}, "prompt_length": 32, "batch_size": 1, "seed": 1337, "pretrained": "gpt2-medium", "benchmark_name": "latency_vs_T", "version": "v4", "version_description": "KV-cache + INT8 + cross-layer sharing", "use_cache": true, "kv_cache_quant": true, "cross_layer_sharing": true, "T": 320, "time_total_ms_median": 1638.255615234375, "time_total_ms_mean": 1638.838623046875, "time_total_ms_std": 8.22424602508545, "time_per_token_ms_median": 5.119548797607422, "time_per_token_ms_std": 0.025700768828392027, "n_samples": 20, "n_outliers_removed": 0}
{"implementation_name": "baseline", "gpu_name": "NVIDIA RTX A6000", "gpu_total_vram": 51033931776, "python_version": "3.11.14", "pytorch_version": "2.9.1+cu128", "cuda_version": "12.8", "dtype": "bfloat16", "model_config": {"n_layer": 24, "n_head": 16, "n_embd": 1024, "block_size": 1024, "vocab_size": 50257, "dropout": 0.0, "bias": true, "kv_cache_quant": true, "cross_layer_sharing": true}, "prompt_length": 32, "batch_size": 1, "seed": 1337, "pretrained": "gpt2-medium", "benchmark_name": "latency_vs_T", "version": "v4", "version_description": "KV-cache + INT8 + cross-layer sharing", "use_cache": true, "kv_cache_quant": true, "cross_layer_sharing": true, "T": 384, "time_total_ms_median": 1972.7103271484375, "time_total_ms_mean": 1973.8492431640625, "time_total_ms_std": 11.35065746307373, "time_per_token_ms_median": 5.137266476949056, "time_per_token_ms_std": 0.02955900381008784, "n_samples": 20, "n_outliers_removed": 0}
{"implementation_name": "baseline", "gpu_name": "NVIDIA RTX A6000", "gpu_total_vram": 51033931776, "python_version": "3.11.14", "pytorch_version": "2.9.1+cu128", "cuda_version": "12.8", "dtype": "bfloat16", "model_config": {"n_layer": 24, "n_head": 16, "n_embd": 1024, "block_size": 1024, "vocab_size": 50257, "dropout": 0.0, "bias": true, "kv_cache_quant": true, "cross_layer_sharing": true}, "prompt_length": 32, "batch_size": 1, "seed": 1337, "pretrained": "gpt2-medium", "benchmark_name": "latency_vs_T", "version": "v4", "version_description": "KV-cache + INT8 + cross-layer sharing", "use_cache": true, "kv_cache_quant": true, "cross_layer_sharing": true, "T": 448, "time_total_ms_median": 2302.718017578125, "time_total_ms_mean": 2299.678466796875, "time_total_ms_std": 11.075504302978516, "time_per_token_ms_median": 5.139995574951172, "time_per_token_ms_std": 0.02472210781914847, "n_samples": 20, "n_outliers_removed": 0}
{"implementation_name": "baseline", "gpu_name": "NVIDIA RTX A6000", "gpu_total_vram": 51033931776, "python_version": "3.11.14", "pytorch_version": "2.9.1+cu128", "cuda_version": "12.8", "dtype": "bfloat16", "model_config": {"n_layer": 24, "n_head": 16, "n_embd": 1024, "block_size": 1024, "vocab_size": 50257, "dropout": 0.0, "bias": true, "kv_cache_quant": true, "cross_layer_sharing": true}, "prompt_length": 32, "batch_size": 1, "seed": 1337, "pretrained": "gpt2-medium", "benchmark_name": "latency_vs_T", "version": "v4", "version_description": "KV-cache + INT8 + cross-layer sharing", "use_cache": true, "kv_cache_quant": true, "cross_layer_sharing": true, "T": 512, "time_total_ms_median": 2622.423095703125, "time_total_ms_mean": 2621.921875, "time_total_ms_std": 6.528759956359863, "time_per_token_ms_median": 5.121920108795166, "time_per_token_ms_std": 0.012751484289765358, "n_samples": 18, "n_outliers_removed": 2}
{"implementation_name": "baseline", "gpu_name": "NVIDIA RTX A6000", "gpu_total_vram": 51033931776, "python_version": "3.11.14", "pytorch_version": "2.9.1+cu128", "cuda_version": "12.8", "dtype": "bfloat16", "model_config": {"n_layer": 24, "n_head": 16, "n_embd": 1024, "block_size": 1024, "vocab_size": 50257, "dropout": 0.0, "bias": true, "kv_cache_quant": true, "cross_layer_sharing": true}, "prompt_length": 32, "batch_size": 1, "seed": 1337, "pretrained": "gpt2-medium", "benchmark_name": "latency_vs_T", "version": "v4", "version_description": "KV-cache + INT8 + cross-layer sharing", "use_cache": true, "kv_cache_quant": true, "cross_layer_sharing": true, "T": 640, "time_total_ms_median": 3283.60546875, "time_total_ms_mean": 3282.428466796875, "time_total_ms_std": 16.657285690307617, "time_per_token_ms_median": 5.130633544921875, "time_per_token_ms_std": 0.026027008891105652, "n_samples": 20, "n_outliers_removed": 0}
{"implementation_name": "baseline", "gpu_name": "NVIDIA RTX A6000", "gpu_total_vram": 51033931776, "python_version": "3.11.14", "pytorch_version": "2.9.1+cu128", "cuda_version": "12.8", "dtype": "bfloat16", "model_config": {"n_layer": 24, "n_head": 16, "n_embd": 1024, "block_size": 1024, "vocab_size": 50257, "dropout": 0.0, "bias": true, "kv_cache_quant": true, "cross_layer_sharing": true}, "prompt_length": 32, "batch_size": 1, "seed": 1337, "pretrained": "gpt2-medium", "benchmark_name": "latency_vs_T", "version": "v4", "version_description": "KV-cache + INT8 + cross-layer sharing", "use_cache": true, "kv_cache_quant": true, "cross_layer_sharing": true, "T": 768, "time_total_ms_median": 3953.387451171875, "time_total_ms_mean": 3956.46728515625, "time_total_ms_std": 17.502422332763672, "time_per_token_ms_median": 5.147639910380046, "time_per_token_ms_std": 0.022789612412452698, "n_samples": 20, "n_outliers_removed": 0}
{"implementation_name": "baseline", "gpu_name": "NVIDIA RTX A6000", "gpu_total_vram": 51033931776, "python_version": "3.11.14", "pytorch_version": "2.9.1+cu128", "cuda_version": "12.8", "dtype": "bfloat16", "model_config": {"n_layer": 24, "n_head": 16, "n_embd": 1024, "block_size": 1024, "vocab_size": 50257, "dropout": 0.0, "bias": true, "kv_cache_quant": true, "cross_layer_sharing": true}, "prompt_length": 32, "batch_size": 1, "seed": 1337, "pretrained": "gpt2-medium", "benchmark_name": "latency_vs_T", "version": "v4", "version_description": "KV-cache + INT8 + cross-layer sharing", "use_cache": true, "kv_cache_quant": true, "cross_layer_sharing": true, "T": 896, "time_total_ms_median": 4598.744140625, "time_total_ms_mean": 4596.96484375, "time_total_ms_std": 15.5905179977417, "time_per_token_ms_median": 5.132526942661831, "time_per_token_ms_std": 0.017400131693908145, "n_samples": 19, "n_outliers_removed": 1}
{"implementation_name": "baseline", "gpu_name": "NVIDIA RTX A6000", "gpu_total_vram": 51033931776, "python_version": "3.11.14", "pytorch_version": "2.9.1+cu128", "cuda_version": "12.8", "dtype": "bfloat16", "model_config": {"n_layer": 24, "n_head": 16, "n_embd": 1024, "block_size": 1024, "vocab_size": 50257, "dropout": 0.0, "bias": true, "kv_cache_quant": true, "cross_layer_sharing": true}, "prompt_length": 32, "batch_size": 1, "seed": 1337, "pretrained": "gpt2-medium", "benchmark_name": "latency_vs_T", "version": "v4", "version_description": "KV-cache + INT8 + cross-layer sharing", "use_cache": true, "kv_cache_quant": true, "cross_layer_sharing": true, "T": 1024, "time_total_ms_median": 5273.43603515625, "time_total_ms_mean": 5277.58447265625, "time_total_ms_std": 19.03871726989746, "time_per_token_ms_median": 5.149839878082275, "time_per_token_ms_std": 0.01859249733388424, "n_samples": 20, "n_outliers_removed": 0}
{"implementation_name": "baseline", "gpu_name": "NVIDIA RTX A6000", "gpu_total_vram": 51033931776, "python_version": "3.11.14", "pytorch_version": "2.9.1+cu128", "cuda_version": "12.8", "dtype": "bfloat16", "model_config": {"n_layer": 24, "n_head": 16, "n_embd": 1024, "block_size": 1024, "vocab_size": 50257, "dropout": 0.0, "bias": true, "kv_cache_quant": false, "cross_layer_sharing": false}, "prompt_length": 32, "batch_size": 1, "seed": 1337, "pretrained": "gpt2-medium", "benchmark_name": "vram_vs_T", "version": "v0", "version_description": "No cache (baseline)", "use_cache": false, "kv_cache_quant": false, "cross_layer_sharing": false, "T": 32, "peak_memory_bytes": 771613696, "peak_activation_bytes": 11577856, "baseline_memory_bytes": 760035840}
{"implementation_name": "baseline", "gpu_name": "NVIDIA RTX A6000", "gpu_total_vram": 51033931776, "python_version": "3.11.14", "pytorch_version": "2.9.1+cu128", "cuda_version": "12.8", "dtype": "bfloat16", "model_config": {"n_layer": 24, "n_head": 16, "n_embd": 1024, "block_size": 1024, "vocab_size": 50257, "dropout": 0.0, "bias": true, "kv_cache_quant": false, "cross_layer_sharing": false}, "prompt_length": 32, "batch_size": 1, "seed": 1337, "pretrained": "gpt2-medium", "benchmark_name": "vram_vs_T", "version": "v0", "version_description": "No cache (baseline)", "use_cache": false, "kv_cache_quant": false, "cross_layer_sharing": false, "T": 64, "peak_memory_bytes": 772531712, "peak_activation_bytes": 2927616, "baseline_memory_bytes": 769604096}
{"implementation_name": "baseline", "gpu_name": "NVIDIA RTX A6000", "gpu_total_vram": 51033931776, "python_version": "3.11.14", "pytorch_version": "2.9.1+cu128", "cuda_version": "12.8", "dtype": "bfloat16", "model_config": {"n_layer": 24, "n_head": 16, "n_embd": 1024, "block_size": 1024, "vocab_size": 50257, "dropout": 0.0, "bias": true, "kv_cache_quant": false, "cross_layer_sharing": false}, "prompt_length": 32, "batch_size": 1, "seed": 1337, "pretrained": "gpt2-medium", "benchmark_name": "vram_vs_T", "version": "v0", "version_description": "No cache (baseline)", "use_cache": false, "kv_cache_quant": false, "cross_layer_sharing": false, "T": 96, "peak_memory_bytes": 773449216, "peak_activation_bytes": 3845120, "baseline_memory_bytes": 769604096}
{"implementation_name": "baseline", "gpu_name": "NVIDIA RTX A6000", "gpu_total_vram": 51033931776, "python_version": "3.11.14", "pytorch_version": "2.9.1+cu128", "cuda_version": "12.8", "dtype": "bfloat16", "model_config": {"n_layer": 24, "n_head": 16, "n_embd": 1024, "block_size": 1024, "vocab_size": 50257, "dropout": 0.0, "bias": true, "kv_cache_quant": false, "cross_layer_sharing": false}, "prompt_length": 32, "batch_size": 1, "seed": 1337, "pretrained": "gpt2-medium", "benchmark_name": "vram_vs_T", "version": "v0", "version_description": "No cache (baseline)", "use_cache": false, "kv_cache_quant": false, "cross_layer_sharing": false, "T": 128, "peak_memory_bytes": 774995968, "peak_activation_bytes": 5391872, "baseline_memory_bytes": 769604096}
{"implementation_name": "baseline", "gpu_name": "NVIDIA RTX A6000", "gpu_total_vram": 51033931776, "python_version": "3.11.14", "pytorch_version": "2.9.1+cu128", "cuda_version": "12.8", "dtype": "bfloat16", "model_config": {"n_layer": 24, "n_head": 16, "n_embd": 1024, "block_size": 1024, "vocab_size": 50257, "dropout": 0.0, "bias": true, "kv_cache_quant": false, "cross_layer_sharing": false}, "prompt_length": 32, "batch_size": 1, "seed": 1337, "pretrained": "gpt2-medium", "benchmark_name": "vram_vs_T", "version": "v0", "version_description": "No cache (baseline)", "use_cache": false, "kv_cache_quant": false, "cross_layer_sharing": false, "T": 160, "peak_memory_bytes": 775651328, "peak_activation_bytes": 6047232, "baseline_memory_bytes": 769604096}
{"implementation_name": "baseline", "gpu_name": "NVIDIA RTX A6000", "gpu_total_vram": 51033931776, "python_version": "3.11.14", "pytorch_version": "2.9.1+cu128", "cuda_version": "12.8", "dtype": "bfloat16", "model_config": {"n_layer": 24, "n_head": 16, "n_embd": 1024, "block_size": 1024, "vocab_size": 50257, "dropout": 0.0, "bias": true, "kv_cache_quant": false, "cross_layer_sharing": false}, "prompt_length": 32, "batch_size": 1, "seed": 1337, "pretrained": "gpt2-medium", "benchmark_name": "vram_vs_T", "version": "v0", "version_description": "No cache (baseline)", "use_cache": false, "kv_cache_quant": false, "cross_layer_sharing": false, "T": 192, "peak_memory_bytes": 776307200, "peak_activation_bytes": 6703104, "baseline_memory_bytes": 769604096}
{"implementation_name": "baseline", "gpu_name": "NVIDIA RTX A6000", "gpu_total_vram": 51033931776, "python_version": "3.11.14", "pytorch_version": "2.9.1+cu128", "cuda_version": "12.8", "dtype": "bfloat16", "model_config": {"n_layer": 24, "n_head": 16, "n_embd": 1024, "block_size": 1024, "vocab_size": 50257, "dropout": 0.0, "bias": true, "kv_cache_quant": false, "cross_layer_sharing": false}, "prompt_length": 32, "batch_size": 1, "seed": 1337, "pretrained": "gpt2-medium", "benchmark_name": "vram_vs_T", "version": "v0", "version_description": "No cache (baseline)", "use_cache": false, "kv_cache_quant": false, "cross_layer_sharing": false, "T": 224, "peak_memory_bytes": 777136640, "peak_activation_bytes": 7532544, "baseline_memory_bytes": 769604096}
{"implementation_name": "baseline", "gpu_name": "NVIDIA RTX A6000", "gpu_total_vram": 51033931776, "python_version": "3.11.14", "pytorch_version": "2.9.1+cu128", "cuda_version": "12.8", "dtype": "bfloat16", "model_config": {"n_layer": 24, "n_head": 16, "n_embd": 1024, "block_size": 1024, "vocab_size": 50257, "dropout": 0.0, "bias": true, "kv_cache_quant": false, "cross_layer_sharing": false}, "prompt_length": 32, "batch_size": 1, "seed": 1337, "pretrained": "gpt2-medium", "benchmark_name": "vram_vs_T", "version": "v0", "version_description": "No cache (baseline)", "use_cache": false, "kv_cache_quant": false, "cross_layer_sharing": false, "T": 256, "peak_memory_bytes": 778038272, "peak_activation_bytes": 8434176, "baseline_memory_bytes": 769604096}
{"implementation_name": "baseline", "gpu_name": "NVIDIA RTX A6000", "gpu_total_vram": 51033931776, "python_version": "3.11.14", "pytorch_version": "2.9.1+cu128", "cuda_version": "12.8", "dtype": "bfloat16", "model_config": {"n_layer": 24, "n_head": 16, "n_embd": 1024, "block_size": 1024, "vocab_size": 50257, "dropout": 0.0, "bias": true, "kv_cache_quant": false, "cross_layer_sharing": false}, "prompt_length": 32, "batch_size": 1, "seed": 1337, "pretrained": "gpt2-medium", "benchmark_name": "vram_vs_T", "version": "v0", "version_description": "No cache (baseline)", "use_cache": false, "kv_cache_quant": false, "cross_layer_sharing": false, "T": 320, "peak_memory_bytes": 779873792, "peak_activation_bytes": 10269696, "baseline_memory_bytes": 769604096}
{"implementation_name": "baseline", "gpu_name": "NVIDIA RTX A6000", "gpu_total_vram": 51033931776, "python_version": "3.11.14", "pytorch_version": "2.9.1+cu128", "cuda_version": "12.8", "dtype": "bfloat16", "model_config": {"n_layer": 24, "n_head": 16, "n_embd": 1024, "block_size": 1024, "vocab_size": 50257, "dropout": 0.0, "bias": true, "kv_cache_quant": false, "cross_layer_sharing": false}, "prompt_length": 32, "batch_size": 1, "seed": 1337, "pretrained": "gpt2-medium", "benchmark_name": "vram_vs_T", "version": "v0", "version_description": "No cache (baseline)", "use_cache": false, "kv_cache_quant": false, "cross_layer_sharing": false, "T": 384, "peak_memory_bytes": 782503936, "peak_activation_bytes": 12899840, "baseline_memory_bytes": 769604096}
{"implementation_name": "baseline", "gpu_name": "NVIDIA RTX A6000", "gpu_total_vram": 51033931776, "python_version": "3.11.14", "pytorch_version": "2.9.1+cu128", "cuda_version": "12.8", "dtype": "bfloat16", "model_config": {"n_layer": 24, "n_head": 16, "n_embd": 1024, "block_size": 1024, "vocab_size": 50257, "dropout": 0.0, "bias": true, "kv_cache_quant": false, "cross_layer_sharing": false}, "prompt_length": 32, "batch_size": 1, "seed": 1337, "pretrained": "gpt2-medium", "benchmark_name": "vram_vs_T", "version": "v0", "version_description": "No cache (baseline)", "use_cache": false, "kv_cache_quant": false, "cross_layer_sharing": false, "T": 448, "peak_memory_bytes": 783815168, "peak_activation_bytes": 14211072, "baseline_memory_bytes": 769604096}
{"implementation_name": "baseline", "gpu_name": "NVIDIA RTX A6000", "gpu_total_vram": 51033931776, "python_version": "3.11.14", "pytorch_version": "2.9.1+cu128", "cuda_version": "12.8", "dtype": "bfloat16", "model_config": {"n_layer": 24, "n_head": 16, "n_embd": 1024, "block_size": 1024, "vocab_size": 50257, "dropout": 0.0, "bias": true, "kv_cache_quant": false, "cross_layer_sharing": false}, "prompt_length": 32, "batch_size": 1, "seed": 1337, "pretrained": "gpt2-medium", "benchmark_name": "vram_vs_T", "version": "v0", "version_description": "No cache (baseline)", "use_cache": false, "kv_cache_quant": false, "cross_layer_sharing": false, "T": 512, "peak_memory_bytes": 787788800, "peak_activation_bytes": 18184704, "baseline_memory_bytes": 769604096}
{"implementation_name": "baseline", "gpu_name": "NVIDIA RTX A6000", "gpu_total_vram": 51033931776, "python_version": "3.11.14", "pytorch_version": "2.9.1+cu128", "cuda_version": "12.8", "dtype": "bfloat16", "model_config": {"n_layer": 24, "n_head": 16, "n_embd": 1024, "block_size": 1024, "vocab_size": 50257, "dropout": 0.0, "bias": true, "kv_cache_quant": false, "cross_layer_sharing": false}, "prompt_length": 32, "batch_size": 1, "seed": 1337, "pretrained": "gpt2-medium", "benchmark_name": "vram_vs_T", "version": "v0", "version_description": "No cache (baseline)", "use_cache": false, "kv_cache_quant": false, "cross_layer_sharing": false, "T": 640, "peak_memory_bytes": 789764096, "peak_activation_bytes": 20160000, "baseline_memory_bytes": 769604096}
{"implementation_name": "baseline", "gpu_name": "NVIDIA RTX A6000", "gpu_total_vram": 51033931776, "python_version": "3.11.14", "pytorch_version": "2.9.1+cu128", "cuda_version": "12.8", "dtype": "bfloat16", "model_config": {"n_layer": 24, "n_head": 16, "n_embd": 1024, "block_size": 1024, "vocab_size": 50257, "dropout": 0.0, "bias": true, "kv_cache_quant": false, "cross_layer_sharing": false}, "prompt_length": 32, "batch_size": 1, "seed": 1337, "pretrained": "gpt2-medium", "benchmark_name": "vram_vs_T", "version": "v0", "version_description": "No cache (baseline)", "use_cache": false, "kv_cache_quant": false, "cross_layer_sharing": false, "T": 768, "peak_memory_bytes": 793938944, "peak_activation_bytes": 24334848, "baseline_memory_bytes": 769604096}
{"implementation_name": "baseline", "gpu_name": "NVIDIA RTX A6000", "gpu_total_vram": 51033931776, "python_version": "3.11.14", "pytorch_version": "2.9.1+cu128", "cuda_version": "12.8", "dtype": "bfloat16", "model_config": {"n_layer": 24, "n_head": 16, "n_embd": 1024, "block_size": 1024, "vocab_size": 50257, "dropout": 0.0, "bias": true, "kv_cache_quant": false, "cross_layer_sharing": false}, "prompt_length": 32, "batch_size": 1, "seed": 1337, "pretrained": "gpt2-medium", "benchmark_name": "vram_vs_T", "version": "v0", "version_description": "No cache (baseline)", "use_cache": false, "kv_cache_quant": false, "cross_layer_sharing": false, "T": 896, "peak_memory_bytes": 797419520, "peak_activation_bytes": 27815424, "baseline_memory_bytes": 769604096}
{"implementation_name": "baseline", "gpu_name": "NVIDIA RTX A6000", "gpu_total_vram": 51033931776, "python_version": "3.11.14", "pytorch_version": "2.9.1+cu128", "cuda_version": "12.8", "dtype": "bfloat16", "model_config": {"n_layer": 24, "n_head": 16, "n_embd": 1024, "block_size": 1024, "vocab_size": 50257, "dropout": 0.0, "bias": true, "kv_cache_quant": false, "cross_layer_sharing": false}, "prompt_length": 32, "batch_size": 1, "seed": 1337, "pretrained": "gpt2-medium", "benchmark_name": "vram_vs_T", "version": "v0", "version_description": "No cache (baseline)", "use_cache": false, "kv_cache_quant": false, "cross_layer_sharing": false, "T": 1024, "peak_memory_bytes": 799175680, "peak_activation_bytes": 29571584, "baseline_memory_bytes": 769604096}
{"implementation_name": "baseline", "gpu_name": "NVIDIA RTX A6000", "gpu_total_vram": 51033931776, "python_version": "3.11.14", "pytorch_version": "2.9.1+cu128", "cuda_version": "12.8", "dtype": "bfloat16", "model_config": {"n_layer": 24, "n_head": 16, "n_embd": 1024, "block_size": 1024, "vocab_size": 50257, "dropout": 0.0, "bias": true, "kv_cache_quant": false, "cross_layer_sharing": false}, "prompt_length": 32, "batch_size": 1, "seed": 1337, "pretrained": "gpt2-medium", "benchmark_name": "vram_vs_T", "version": "v1", "version_description": "KV-cache enabled", "use_cache": true, "kv_cache_quant": false, "cross_layer_sharing": false, "T": 32, "peak_memory_bytes": 871185920, "peak_activation_bytes": 101581824, "baseline_memory_bytes": 769604096}
{"implementation_name": "baseline", "gpu_name": "NVIDIA RTX A6000", "gpu_total_vram": 51033931776, "python_version": "3.11.14", "pytorch_version": "2.9.1+cu128", "cuda_version": "12.8", "dtype": "bfloat16", "model_config": {"n_layer": 24, "n_head": 16, "n_embd": 1024, "block_size": 1024, "vocab_size": 50257, "dropout": 0.0, "bias": true, "kv_cache_quant": false, "cross_layer_sharing": false}, "prompt_length": 32, "batch_size": 1, "seed": 1337, "pretrained": "gpt2-medium", "benchmark_name": "vram_vs_T", "version": "v1", "version_description": "KV-cache enabled", "use_cache": true, "kv_cache_quant": false, "cross_layer_sharing": false, "T": 64, "peak_memory_bytes": 871186432, "peak_activation_bytes": 101582336, "baseline_memory_bytes": 769604096}
{"implementation_name": "baseline", "gpu_name": "NVIDIA RTX A6000", "gpu_total_vram": 51033931776, "python_version": "3.11.14", "pytorch_version": "2.9.1+cu128", "cuda_version": "12.8", "dtype": "bfloat16", "model_config": {"n_layer": 24, "n_head": 16, "n_embd": 1024, "block_size": 1024, "vocab_size": 50257, "dropout": 0.0, "bias": true, "kv_cache_quant": false, "cross_layer_sharing": false}, "prompt_length": 32, "batch_size": 1, "seed": 1337, "pretrained": "gpt2-medium", "benchmark_name": "vram_vs_T", "version": "v1", "version_description": "KV-cache enabled", "use_cache": true, "kv_cache_quant": false, "cross_layer_sharing": false, "T": 96, "peak_memory_bytes": 871186432, "peak_activation_bytes": 101582336, "baseline_memory_bytes": 769604096}
{"implementation_name": "baseline", "gpu_name": "NVIDIA RTX A6000", "gpu_total_vram": 51033931776, "python_version": "3.11.14", "pytorch_version": "2.9.1+cu128", "cuda_version": "12.8", "dtype": "bfloat16", "model_config": {"n_layer": 24, "n_head": 16, "n_embd": 1024, "block_size": 1024, "vocab_size": 50257, "dropout": 0.0, "bias": true, "kv_cache_quant": false, "cross_layer_sharing": false}, "prompt_length": 32, "batch_size": 1, "seed": 1337, "pretrained": "gpt2-medium", "benchmark_name": "vram_vs_T", "version": "v1", "version_description": "KV-cache enabled", "use_cache": true, "kv_cache_quant": false, "cross_layer_sharing": false, "T": 128, "peak_memory_bytes": 871186944, "peak_activation_bytes": 101582848, "baseline_memory_bytes": 769604096}
{"implementation_name": "baseline", "gpu_name": "NVIDIA RTX A6000", "gpu_total_vram": 51033931776, "python_version": "3.11.14", "pytorch_version": "2.9.1+cu128", "cuda_version": "12.8", "dtype": "bfloat16", "model_config": {"n_layer": 24, "n_head": 16, "n_embd": 1024, "block_size": 1024, "vocab_size": 50257, "dropout": 0.0, "bias": true, "kv_cache_quant": false, "cross_layer_sharing": false}, "prompt_length": 32, "batch_size": 1, "seed": 1337, "pretrained": "gpt2-medium", "benchmark_name": "vram_vs_T", "version": "v1", "version_description": "KV-cache enabled", "use_cache": true, "kv_cache_quant": false, "cross_layer_sharing": false, "T": 160, "peak_memory_bytes": 871186944, "peak_activation_bytes": 101582848, "baseline_memory_bytes": 769604096}
{"implementation_name": "baseline", "gpu_name": "NVIDIA RTX A6000", "gpu_total_vram": 51033931776, "python_version": "3.11.14", "pytorch_version": "2.9.1+cu128", "cuda_version": "12.8", "dtype": "bfloat16", "model_config": {"n_layer": 24, "n_head": 16, "n_embd": 1024, "block_size": 1024, "vocab_size": 50257, "dropout": 0.0, "bias": true, "kv_cache_quant": false, "cross_layer_sharing": false}, "prompt_length": 32, "batch_size": 1, "seed": 1337, "pretrained": "gpt2-medium", "benchmark_name": "vram_vs_T", "version": "v1", "version_description": "KV-cache enabled", "use_cache": true, "kv_cache_quant": false, "cross_layer_sharing": false, "T": 192, "peak_memory_bytes": 871187456, "peak_activation_bytes": 101583360, "baseline_memory_bytes": 769604096}
{"implementation_name": "baseline", "gpu_name": "NVIDIA RTX A6000", "gpu_total_vram": 51033931776, "python_version": "3.11.14", "pytorch_version": "2.9.1+cu128", "cuda_version": "12.8", "dtype": "bfloat16", "model_config": {"n_layer": 24, "n_head": 16, "n_embd": 1024, "block_size": 1024, "vocab_size": 50257, "dropout": 0.0, "bias": true, "kv_cache_quant": false, "cross_layer_sharing": false}, "prompt_length": 32, "batch_size": 1, "seed": 1337, "pretrained": "gpt2-medium", "benchmark_name": "vram_vs_T", "version": "v1", "version_description": "KV-cache enabled", "use_cache": true, "kv_cache_quant": false, "cross_layer_sharing": false, "T": 224, "peak_memory_bytes": 871187456, "peak_activation_bytes": 101583360, "baseline_memory_bytes": 769604096}
{"implementation_name": "baseline", "gpu_name": "NVIDIA RTX A6000", "gpu_total_vram": 51033931776, "python_version": "3.11.14", "pytorch_version": "2.9.1+cu128", "cuda_version": "12.8", "dtype": "bfloat16", "model_config": {"n_layer": 24, "n_head": 16, "n_embd": 1024, "block_size": 1024, "vocab_size": 50257, "dropout": 0.0, "bias": true, "kv_cache_quant": false, "cross_layer_sharing": false}, "prompt_length": 32, "batch_size": 1, "seed": 1337, "pretrained": "gpt2-medium", "benchmark_name": "vram_vs_T", "version": "v1", "version_description": "KV-cache enabled", "use_cache": true, "kv_cache_quant": false, "cross_layer_sharing": false, "T": 256, "peak_memory_bytes": 871187968, "peak_activation_bytes": 101583872, "baseline_memory_bytes": 769604096}
{"implementation_name": "baseline", "gpu_name": "NVIDIA RTX A6000", "gpu_total_vram": 51033931776, "python_version": "3.11.14", "pytorch_version": "2.9.1+cu128", "cuda_version": "12.8", "dtype": "bfloat16", "model_config": {"n_layer": 24, "n_head": 16, "n_embd": 1024, "block_size": 1024, "vocab_size": 50257, "dropout": 0.0, "bias": true, "kv_cache_quant": false, "cross_layer_sharing": false}, "prompt_length": 32, "batch_size": 1, "seed": 1337, "pretrained": "gpt2-medium", "benchmark_name": "vram_vs_T", "version": "v1", "version_description": "KV-cache enabled", "use_cache": true, "kv_cache_quant": false, "cross_layer_sharing": false, "T": 320, "peak_memory_bytes": 871188480, "peak_activation_bytes": 101584384, "baseline_memory_bytes": 769604096}
{"implementation_name": "baseline", "gpu_name": "NVIDIA RTX A6000", "gpu_total_vram": 51033931776, "python_version": "3.11.14", "pytorch_version": "2.9.1+cu128", "cuda_version": "12.8", "dtype": "bfloat16", "model_config": {"n_layer": 24, "n_head": 16, "n_embd": 1024, "block_size": 1024, "vocab_size": 50257, "dropout": 0.0, "bias": true, "kv_cache_quant": false, "cross_layer_sharing": false}, "prompt_length": 32, "batch_size": 1, "seed": 1337, "pretrained": "gpt2-medium", "benchmark_name": "vram_vs_T", "version": "v1", "version_description": "KV-cache enabled", "use_cache": true, "kv_cache_quant": false, "cross_layer_sharing": false, "T": 384, "peak_memory_bytes": 871188992, "peak_activation_bytes": 101584896, "baseline_memory_bytes": 769604096}
{"implementation_name": "baseline", "gpu_name": "NVIDIA RTX A6000", "gpu_total_vram": 51033931776, "python_version": "3.11.14", "pytorch_version": "2.9.1+cu128", "cuda_version": "12.8", "dtype": "bfloat16", "model_config": {"n_layer": 24, "n_head": 16, "n_embd": 1024, "block_size": 1024, "vocab_size": 50257, "dropout": 0.0, "bias": true, "kv_cache_quant": false, "cross_layer_sharing": false}, "prompt_length": 32, "batch_size": 1, "seed": 1337, "pretrained": "gpt2-medium", "benchmark_name": "vram_vs_T", "version": "v1", "version_description": "KV-cache enabled", "use_cache": true, "kv_cache_quant": false, "cross_layer_sharing": false, "T": 448, "peak_memory_bytes": 871189504, "peak_activation_bytes": 101585408, "baseline_memory_bytes": 769604096}
{"implementation_name": "baseline", "gpu_name": "NVIDIA RTX A6000", "gpu_total_vram": 51033931776, "python_version": "3.11.14", "pytorch_version": "2.9.1+cu128", "cuda_version": "12.8", "dtype": "bfloat16", "model_config": {"n_layer": 24, "n_head": 16, "n_embd": 1024, "block_size": 1024, "vocab_size": 50257, "dropout": 0.0, "bias": true, "kv_cache_quant": false, "cross_layer_sharing": false}, "prompt_length": 32, "batch_size": 1, "seed": 1337, "pretrained": "gpt2-medium", "benchmark_name": "vram_vs_T", "version": "v1", "version_description": "KV-cache enabled", "use_cache": true, "kv_cache_quant": false, "cross_layer_sharing": false, "T": 512, "peak_memory_bytes": 871190016, "peak_activation_bytes": 101585920, "baseline_memory_bytes": 769604096}
{"implementation_name": "baseline", "gpu_name": "NVIDIA RTX A6000", "gpu_total_vram": 51033931776, "python_version": "3.11.14", "pytorch_version": "2.9.1+cu128", "cuda_version": "12.8", "dtype": "bfloat16", "model_config": {"n_layer": 24, "n_head": 16, "n_embd": 1024, "block_size": 1024, "vocab_size": 50257, "dropout": 0.0, "bias": true, "kv_cache_quant": false, "cross_layer_sharing": false}, "prompt_length": 32, "batch_size": 1, "seed": 1337, "pretrained": "gpt2-medium", "benchmark_name": "vram_vs_T", "version": "v1", "version_description": "KV-cache enabled", "use_cache": true, "kv_cache_quant": false, "cross_layer_sharing": false, "T": 640, "peak_memory_bytes": 871191040, "peak_activation_bytes": 101586944, "baseline_memory_bytes": 769604096}
{"implementation_name": "baseline", "gpu_name": "NVIDIA RTX A6000", "gpu_total_vram": 51033931776, "python_version": "3.11.14", "pytorch_version": "2.9.1+cu128", "cuda_version": "12.8", "dtype": "bfloat16", "model_config": {"n_layer": 24, "n_head": 16, "n_embd": 1024, "block_size": 1024, "vocab_size": 50257, "dropout": 0.0, "bias": true, "kv_cache_quant": false, "cross_layer_sharing": false}, "prompt_length": 32, "batch_size": 1, "seed": 1337, "pretrained": "gpt2-medium", "benchmark_name": "vram_vs_T", "version": "v1", "version_description": "KV-cache enabled", "use_cache": true, "kv_cache_quant": false, "cross_layer_sharing": false, "T": 768, "peak_memory_bytes": 871192064, "peak_activation_bytes": 101587968, "baseline_memory_bytes": 769604096}
{"implementation_name": "baseline", "gpu_name": "NVIDIA RTX A6000", "gpu_total_vram": 51033931776, "python_version": "3.11.14", "pytorch_version": "2.9.1+cu128", "cuda_version": "12.8", "dtype": "bfloat16", "model_config": {"n_layer": 24, "n_head": 16, "n_embd": 1024, "block_size": 1024, "vocab_size": 50257, "dropout": 0.0, "bias": true, "kv_cache_quant": false, "cross_layer_sharing": false}, "prompt_length": 32, "batch_size": 1, "seed": 1337, "pretrained": "gpt2-medium", "benchmark_name": "vram_vs_T", "version": "v1", "version_description": "KV-cache enabled", "use_cache": true, "kv_cache_quant": false, "cross_layer_sharing": false, "T": 896, "peak_memory_bytes": 871193088, "peak_activation_bytes": 101588992, "baseline_memory_bytes": 769604096}
{"implementation_name": "baseline", "gpu_name": "NVIDIA RTX A6000", "gpu_total_vram": 51033931776, "python_version": "3.11.14", "pytorch_version": "2.9.1+cu128", "cuda_version": "12.8", "dtype": "bfloat16", "model_config": {"n_layer": 24, "n_head": 16, "n_embd": 1024, "block_size": 1024, "vocab_size": 50257, "dropout": 0.0, "bias": true, "kv_cache_quant": false, "cross_layer_sharing": false}, "prompt_length": 32, "batch_size": 1, "seed": 1337, "pretrained": "gpt2-medium", "benchmark_name": "vram_vs_T", "version": "v1", "version_description": "KV-cache enabled", "use_cache": true, "kv_cache_quant": false, "cross_layer_sharing": false, "T": 1024, "peak_memory_bytes": 920810496, "peak_activation_bytes": 151206400, "baseline_memory_bytes": 769604096}
{"implementation_name": "baseline", "gpu_name": "NVIDIA RTX A6000", "gpu_total_vram": 51033931776, "python_version": "3.11.14", "pytorch_version": "2.9.1+cu128", "cuda_version": "12.8", "dtype": "bfloat16", "model_config": {"n_layer": 24, "n_head": 16, "n_embd": 1024, "block_size": 1024, "vocab_size": 50257, "dropout": 0.0, "bias": true, "kv_cache_quant": true, "cross_layer_sharing": false}, "prompt_length": 32, "batch_size": 1, "seed": 1337, "pretrained": "gpt2-medium", "benchmark_name": "vram_vs_T", "version": "v2", "version_description": "KV-cache + INT8 quantization", "use_cache": true, "kv_cache_quant": true, "cross_layer_sharing": false, "T": 32, "peak_memory_bytes": 820952576, "peak_activation_bytes": 51348480, "baseline_memory_bytes": 769604096}
{"implementation_name": "baseline", "gpu_name": "NVIDIA RTX A6000", "gpu_total_vram": 51033931776, "python_version": "3.11.14", "pytorch_version": "2.9.1+cu128", "cuda_version": "12.8", "dtype": "bfloat16", "model_config": {"n_layer": 24, "n_head": 16, "n_embd": 1024, "block_size": 1024, "vocab_size": 50257, "dropout": 0.0, "bias": true, "kv_cache_quant": true, "cross_layer_sharing": false}, "prompt_length": 32, "batch_size": 1, "seed": 1337, "pretrained": "gpt2-medium", "benchmark_name": "vram_vs_T", "version": "v2", "version_description": "KV-cache + INT8 quantization", "use_cache": true, "kv_cache_quant": true, "cross_layer_sharing": false, "T": 64, "peak_memory_bytes": 820953088, "peak_activation_bytes": 51348992, "baseline_memory_bytes": 769604096}
{"implementation_name": "baseline", "gpu_name": "NVIDIA RTX A6000", "gpu_total_vram": 51033931776, "python_version": "3.11.14", "pytorch_version": "2.9.1+cu128", "cuda_version": "12.8", "dtype": "bfloat16", "model_config": {"n_layer": 24, "n_head": 16, "n_embd": 1024, "block_size": 1024, "vocab_size": 50257, "dropout": 0.0, "bias": true, "kv_cache_quant": true, "cross_layer_sharing": false}, "prompt_length": 32, "batch_size": 1, "seed": 1337, "pretrained": "gpt2-medium", "benchmark_name": "vram_vs_T", "version": "v2", "version_description": "KV-cache + INT8 quantization", "use_cache": true, "kv_cache_quant": true, "cross_layer_sharing": false, "T": 96, "peak_memory_bytes": 821033472, "peak_activation_bytes": 51429376, "baseline_memory_bytes": 769604096}
{"implementation_name": "baseline", "gpu_name": "NVIDIA RTX A6000", "gpu_total_vram": 51033931776, "python_version": "3.11.14", "pytorch_version": "2.9.1+cu128", "cuda_version": "12.8", "dtype": "bfloat16", "model_config": {"n_layer": 24, "n_head": 16, "n_embd": 1024, "block_size": 1024, "vocab_size": 50257, "dropout": 0.0, "bias": true, "kv_cache_quant": true, "cross_layer_sharing": false}, "prompt_length": 32, "batch_size": 1, "seed": 1337, "pretrained": "gpt2-medium", "benchmark_name": "vram_vs_T", "version": "v2", "version_description": "KV-cache + INT8 quantization", "use_cache": true, "kv_cache_quant": true, "cross_layer_sharing": false, "T": 128, "peak_memory_bytes": 821230592, "peak_activation_bytes": 51626496, "baseline_memory_bytes": 769604096}
{"implementation_name": "baseline", "gpu_name": "NVIDIA RTX A6000", "gpu_total_vram": 51033931776, "python_version": "3.11.14", "pytorch_version": "2.9.1+cu128", "cuda_version": "12.8", "dtype": "bfloat16", "model_config": {"n_layer": 24, "n_head": 16, "n_embd": 1024, "block_size": 1024, "vocab_size": 50257, "dropout": 0.0, "bias": true, "kv_cache_quant": true, "cross_layer_sharing": false}, "prompt_length": 32, "batch_size": 1, "seed": 1337, "pretrained": "gpt2-medium", "benchmark_name": "vram_vs_T", "version": "v2", "version_description": "KV-cache + INT8 quantization", "use_cache": true, "kv_cache_quant": true, "cross_layer_sharing": false, "T": 160, "peak_memory_bytes": 821427200, "peak_activation_bytes": 51823104, "baseline_memory_bytes": 769604096}
{"implementation_name": "baseline", "gpu_name": "NVIDIA RTX A6000", "gpu_total_vram": 51033931776, "python_version": "3.11.14", "pytorch_version": "2.9.1+cu128", "cuda_version": "12.8", "dtype": "bfloat16", "model_config": {"n_layer": 24, "n_head": 16, "n_embd": 1024, "block_size": 1024, "vocab_size": 50257, "dropout": 0.0, "bias": true, "kv_cache_quant": true, "cross_layer_sharing": false}, "prompt_length": 32, "batch_size": 1, "seed": 1337, "pretrained": "gpt2-medium", "benchmark_name": "vram_vs_T", "version": "v2", "version_description": "KV-cache + INT8 quantization", "use_cache": true, "kv_cache_quant": true, "cross_layer_sharing": false, "T": 192, "peak_memory_bytes": 821624320, "peak_activation_bytes": 52020224, "baseline_memory_bytes": 769604096}
{"implementation_name": "baseline", "gpu_name": "NVIDIA RTX A6000", "gpu_total_vram": 51033931776, "python_version": "3.11.14", "pytorch_version": "2.9.1+cu128", "cuda_version": "12.8", "dtype": "bfloat16", "model_config": {"n_layer": 24, "n_head": 16, "n_embd": 1024, "block_size": 1024, "vocab_size": 50257, "dropout": 0.0, "bias": true, "kv_cache_quant": true, "cross_layer_sharing": false}, "prompt_length": 32, "batch_size": 1, "seed": 1337, "pretrained": "gpt2-medium", "benchmark_name": "vram_vs_T", "version": "v2", "version_description": "KV-cache + INT8 quantization", "use_cache": true, "kv_cache_quant": true, "cross_layer_sharing": false, "T": 224, "peak_memory_bytes": 821820928, "peak_activation_bytes": 52216832, "baseline_memory_bytes": 769604096}
{"implementation_name": "baseline", "gpu_name": "NVIDIA RTX A6000", "gpu_total_vram": 51033931776, "python_version": "3.11.14", "pytorch_version": "2.9.1+cu128", "cuda_version": "12.8", "dtype": "bfloat16", "model_config": {"n_layer": 24, "n_head": 16, "n_embd": 1024, "block_size": 1024, "vocab_size": 50257, "dropout": 0.0, "bias": true, "kv_cache_quant": true, "cross_layer_sharing": false}, "prompt_length": 32, "batch_size": 1, "seed": 1337, "pretrained": "gpt2-medium", "benchmark_name": "vram_vs_T", "version": "v2", "version_description": "KV-cache + INT8 quantization", "use_cache": true, "kv_cache_quant": true, "cross_layer_sharing": false, "T": 256, "peak_memory_bytes": 822018048, "peak_activation_bytes": 52413952, "baseline_memory_bytes": 769604096}
{"implementation_name": "baseline", "gpu_name": "NVIDIA RTX A6000", "gpu_total_vram": 51033931776, "python_version": "3.11.14", "pytorch_version": "2.9.1+cu128", "cuda_version": "12.8", "dtype": "bfloat16", "model_config": {"n_layer": 24, "n_head": 16, "n_embd": 1024, "block_size": 1024, "vocab_size": 50257, "dropout": 0.0, "bias": true, "kv_cache_quant": true, "cross_layer_sharing": false}, "prompt_length": 32, "batch_size": 1, "seed": 1337, "pretrained": "gpt2-medium", "benchmark_name": "vram_vs_T", "version": "v2", "version_description": "KV-cache + INT8 quantization", "use_cache": true, "kv_cache_quant": true, "cross_layer_sharing": false, "T": 320, "peak_memory_bytes": 822411776, "peak_activation_bytes": 52807680, "baseline_memory_bytes": 769604096}
{"implementation_name": "baseline", "gpu_name": "NVIDIA RTX A6000", "gpu_total_vram": 51033931776, "python_version": "3.11.14", "pytorch_version": "2.9.1+cu128", "cuda_version": "12.8", "dtype": "bfloat16", "model_config": {"n_layer": 24, "n_head": 16, "n_embd": 1024, "block_size": 1024, "vocab_size": 50257, "dropout": 0.0, "bias": true, "kv_cache_quant": true, "cross_layer_sharing": false}, "prompt_length": 32, "batch_size": 1, "seed": 1337, "pretrained": "gpt2-medium", "benchmark_name": "vram_vs_T", "version": "v2", "version_description": "KV-cache + INT8 quantization", "use_cache": true, "kv_cache_quant": true, "cross_layer_sharing": false, "T": 384, "peak_memory_bytes": 822805504, "peak_activation_bytes": 53201408, "baseline_memory_bytes": 769604096}
{"implementation_name": "baseline", "gpu_name": "NVIDIA RTX A6000", "gpu_total_vram": 51033931776, "python_version": "3.11.14", "pytorch_version": "2.9.1+cu128", "cuda_version": "12.8", "dtype": "bfloat16", "model_config": {"n_layer": 24, "n_head": 16, "n_embd": 1024, "block_size": 1024, "vocab_size": 50257, "dropout": 0.0, "bias": true, "kv_cache_quant": true, "cross_layer_sharing": false}, "prompt_length": 32, "batch_size": 1, "seed": 1337, "pretrained": "gpt2-medium", "benchmark_name": "vram_vs_T", "version": "v2", "version_description": "KV-cache + INT8 quantization", "use_cache": true, "kv_cache_quant": true, "cross_layer_sharing": false, "T": 448, "peak_memory_bytes": 823199232, "peak_activation_bytes": 53595136, "baseline_memory_bytes": 769604096}
{"implementation_name": "baseline", "gpu_name": "NVIDIA RTX A6000", "gpu_total_vram": 51033931776, "python_version": "3.11.14", "pytorch_version": "2.9.1+cu128", "cuda_version": "12.8", "dtype": "bfloat16", "model_config": {"n_layer": 24, "n_head": 16, "n_embd": 1024, "block_size": 1024, "vocab_size": 50257, "dropout": 0.0, "bias": true, "kv_cache_quant": true, "cross_layer_sharing": false}, "prompt_length": 32, "batch_size": 1, "seed": 1337, "pretrained": "gpt2-medium", "benchmark_name": "vram_vs_T", "version": "v2", "version_description": "KV-cache + INT8 quantization", "use_cache": true, "kv_cache_quant": true, "cross_layer_sharing": false, "T": 512, "peak_memory_bytes": 825266176, "peak_activation_bytes": 55662080, "baseline_memory_bytes": 769604096}
{"implementation_name": "baseline", "gpu_name": "NVIDIA RTX A6000", "gpu_total_vram": 51033931776, "python_version": "3.11.14", "pytorch_version": "2.9.1+cu128", "cuda_version": "12.8", "dtype": "bfloat16", "model_config": {"n_layer": 24, "n_head": 16, "n_embd": 1024, "block_size": 1024, "vocab_size": 50257, "dropout": 0.0, "bias": true, "kv_cache_quant": true, "cross_layer_sharing": false}, "prompt_length": 32, "batch_size": 1, "seed": 1337, "pretrained": "gpt2-medium", "benchmark_name": "vram_vs_T", "version": "v2", "version_description": "KV-cache + INT8 quantization", "use_cache": true, "kv_cache_quant": true, "cross_layer_sharing": false, "T": 640, "peak_memory_bytes": 825529344, "peak_activation_bytes": 55925248, "baseline_memory_bytes": 769604096}
{"implementation_name": "baseline", "gpu_name": "NVIDIA RTX A6000", "gpu_total_vram": 51033931776, "python_version": "3.11.14", "pytorch_version": "2.9.1+cu128", "cuda_version": "12.8", "dtype": "bfloat16", "model_config": {"n_layer": 24, "n_head": 16, "n_embd": 1024, "block_size": 1024, "vocab_size": 50257, "dropout": 0.0, "bias": true, "kv_cache_quant": true, "cross_layer_sharing": false}, "prompt_length": 32, "batch_size": 1, "seed": 1337, "pretrained": "gpt2-medium", "benchmark_name": "vram_vs_T", "version": "v2", "version_description": "KV-cache + INT8 quantization", "use_cache": true, "kv_cache_quant": true, "cross_layer_sharing": false, "T": 768, "peak_memory_bytes": 825792512, "peak_activation_bytes": 56188416, "baseline_memory_bytes": 769604096}
{"implementation_name": "baseline", "gpu_name": "NVIDIA RTX A6000", "gpu_total_vram": 51033931776, "python_version": "3.11.14", "pytorch_version": "2.9.1+cu128", "cuda_version": "12.8", "dtype": "bfloat16", "model_config": {"n_layer": 24, "n_head": 16, "n_embd": 1024, "block_size": 1024, "vocab_size": 50257, "dropout": 0.0, "bias": true, "kv_cache_quant": true, "cross_layer_sharing": false}, "prompt_length": 32, "batch_size": 1, "seed": 1337, "pretrained": "gpt2-medium", "benchmark_name": "vram_vs_T", "version": "v2", "version_description": "KV-cache + INT8 quantization", "use_cache": true, "kv_cache_quant": true, "cross_layer_sharing": false, "T": 896, "peak_memory_bytes": 826055680, "peak_activation_bytes": 56451584, "baseline_memory_bytes": 769604096}
{"implementation_name": "baseline", "gpu_name": "NVIDIA RTX A6000", "gpu_total_vram": 51033931776, "python_version": "3.11.14", "pytorch_version": "2.9.1+cu128", "cuda_version": "12.8", "dtype": "bfloat16", "model_config": {"n_layer": 24, "n_head": 16, "n_embd": 1024, "block_size": 1024, "vocab_size": 50257, "dropout": 0.0, "bias": true, "kv_cache_quant": true, "cross_layer_sharing": false}, "prompt_length": 32, "batch_size": 1, "seed": 1337, "pretrained": "gpt2-medium", "benchmark_name": "vram_vs_T", "version": "v2", "version_description": "KV-cache + INT8 quantization", "use_cache": true, "kv_cache_quant": true, "cross_layer_sharing": false, "T": 1024, "peak_memory_bytes": 845411328, "peak_activation_bytes": 75807232, "baseline_memory_bytes": 769604096}
{"implementation_name": "baseline", "gpu_name": "NVIDIA RTX A6000", "gpu_total_vram": 51033931776, "python_version": "3.11.14", "pytorch_version": "2.9.1+cu128", "cuda_version": "12.8", "dtype": "bfloat16", "model_config": {"n_layer": 24, "n_head": 16, "n_embd": 1024, "block_size": 1024, "vocab_size": 50257, "dropout": 0.0, "bias": true, "kv_cache_quant": false, "cross_layer_sharing": true}, "prompt_length": 32, "batch_size": 1, "seed": 1337, "pretrained": "gpt2-medium", "benchmark_name": "vram_vs_T", "version": "v3", "version_description": "KV-cache + cross-layer sharing", "use_cache": true, "kv_cache_quant": false, "cross_layer_sharing": true, "T": 32, "peak_memory_bytes": 820854272, "peak_activation_bytes": 51250176, "baseline_memory_bytes": 769604096}
{"implementation_name": "baseline", "gpu_name": "NVIDIA RTX A6000", "gpu_total_vram": 51033931776, "python_version": "3.11.14", "pytorch_version": "2.9.1+cu128", "cuda_version": "12.8", "dtype": "bfloat16", "model_config": {"n_layer": 24, "n_head": 16, "n_embd": 1024, "block_size": 1024, "vocab_size": 50257, "dropout": 0.0, "bias": true, "kv_cache_quant": false, "cross_layer_sharing": true}, "prompt_length": 32, "batch_size": 1, "seed": 1337, "pretrained": "gpt2-medium", "benchmark_name": "vram_vs_T", "version": "v3", "version_description": "KV-cache + cross-layer sharing", "use_cache": true, "kv_cache_quant": false, "cross_layer_sharing": true, "T": 64, "peak_memory_bytes": 820854784, "peak_activation_bytes": 51250688, "baseline_memory_bytes": 769604096}
{"implementation_name": "baseline", "gpu_name": "NVIDIA RTX A6000", "gpu_total_vram": 51033931776, "python_version": "3.11.14", "pytorch_version": "2.9.1+cu128", "cuda_version": "12.8", "dtype": "bfloat16", "model_config": {"n_layer": 24, "n_head": 16, "n_embd": 1024, "block_size": 1024, "vocab_size": 50257, "dropout": 0.0, "bias": true, "kv_cache_quant": false, "cross_layer_sharing": true}, "prompt_length": 32, "batch_size": 1, "seed": 1337, "pretrained": "gpt2-medium", "benchmark_name": "vram_vs_T", "version": "v3", "version_description": "KV-cache + cross-layer sharing", "use_cache": true, "kv_cache_quant": false, "cross_layer_sharing": true, "T": 96, "peak_memory_bytes": 820854784, "peak_activation_bytes": 51250688, "baseline_memory_bytes": 769604096}
{"implementation_name": "baseline", "gpu_name": "NVIDIA RTX A6000", "gpu_total_vram": 51033931776, "python_version": "3.11.14", "pytorch_version": "2.9.1+cu128", "cuda_version": "12.8", "dtype": "bfloat16", "model_config": {"n_layer": 24, "n_head": 16, "n_embd": 1024, "block_size": 1024, "vocab_size": 50257, "dropout": 0.0, "bias": true, "kv_cache_quant": false, "cross_layer_sharing": true}, "prompt_length": 32, "batch_size": 1, "seed": 1337, "pretrained": "gpt2-medium", "benchmark_name": "vram_vs_T", "version": "v3", "version_description": "KV-cache + cross-layer sharing", "use_cache": true, "kv_cache_quant": false, "cross_layer_sharing": true, "T": 128, "peak_memory_bytes": 820855296, "peak_activation_bytes": 51251200, "baseline_memory_bytes": 769604096}
{"implementation_name": "baseline", "gpu_name": "NVIDIA RTX A6000", "gpu_total_vram": 51033931776, "python_version": "3.11.14", "pytorch_version": "2.9.1+cu128", "cuda_version": "12.8", "dtype": "bfloat16", "model_config": {"n_layer": 24, "n_head": 16, "n_embd": 1024, "block_size": 1024, "vocab_size": 50257, "dropout": 0.0, "bias": true, "kv_cache_quant": false, "cross_layer_sharing": true}, "prompt_length": 32, "batch_size": 1, "seed": 1337, "pretrained": "gpt2-medium", "benchmark_name": "vram_vs_T", "version": "v3", "version_description": "KV-cache + cross-layer sharing", "use_cache": true, "kv_cache_quant": false, "cross_layer_sharing": true, "T": 160, "peak_memory_bytes": 820855296, "peak_activation_bytes": 51251200, "baseline_memory_bytes": 769604096}
{"implementation_name": "baseline", "gpu_name": "NVIDIA RTX A6000", "gpu_total_vram": 51033931776, "python_version": "3.11.14", "pytorch_version": "2.9.1+cu128", "cuda_version": "12.8", "dtype": "bfloat16", "model_config": {"n_layer": 24, "n_head": 16, "n_embd": 1024, "block_size": 1024, "vocab_size": 50257, "dropout": 0.0, "bias": true, "kv_cache_quant": false, "cross_layer_sharing": true}, "prompt_length": 32, "batch_size": 1, "seed": 1337, "pretrained": "gpt2-medium", "benchmark_name": "vram_vs_T", "version": "v3", "version_description": "KV-cache + cross-layer sharing", "use_cache": true, "kv_cache_quant": false, "cross_layer_sharing": true, "T": 192, "peak_memory_bytes": 820855808, "peak_activation_bytes": 51251712, "baseline_memory_bytes": 769604096}
{"implementation_name": "baseline", "gpu_name": "NVIDIA RTX A6000", "gpu_total_vram": 51033931776, "python_version": "3.11.14", "pytorch_version": "2.9.1+cu128", "cuda_version": "12.8", "dtype": "bfloat16", "model_config": {"n_layer": 24, "n_head": 16, "n_embd": 1024, "block_size": 1024, "vocab_size": 50257, "dropout": 0.0, "bias": true, "kv_cache_quant": false, "cross_layer_sharing": true}, "prompt_length": 32, "batch_size": 1, "seed": 1337, "pretrained": "gpt2-medium", "benchmark_name": "vram_vs_T", "version": "v3", "version_description": "KV-cache + cross-layer sharing", "use_cache": true, "kv_cache_quant": false, "cross_layer_sharing": true, "T": 224, "peak_memory_bytes": 820855808, "peak_activation_bytes": 51251712, "baseline_memory_bytes": 769604096}
{"implementation_name": "baseline", "gpu_name": "NVIDIA RTX A6000", "gpu_total_vram": 51033931776, "python_version": "3.11.14", "pytorch_version": "2.9.1+cu128", "cuda_version": "12.8", "dtype": "bfloat16", "model_config": {"n_layer": 24, "n_head": 16, "n_embd": 1024, "block_size": 1024, "vocab_size": 50257, "dropout": 0.0, "bias": true, "kv_cache_quant": false, "cross_layer_sharing": true}, "prompt_length": 32, "batch_size": 1, "seed": 1337, "pretrained": "gpt2-medium", "benchmark_name": "vram_vs_T", "version": "v3", "version_description": "KV-cache + cross-layer sharing", "use_cache": true, "kv_cache_quant": false, "cross_layer_sharing": true, "T": 256, "peak_memory_bytes": 820856320, "peak_activation_bytes": 51252224, "baseline_memory_bytes": 769604096}
{"implementation_name": "baseline", "gpu_name": "NVIDIA RTX A6000", "gpu_total_vram": 51033931776, "python_version": "3.11.14", "pytorch_version": "2.9.1+cu128", "cuda_version": "12.8", "dtype": "bfloat16", "model_config": {"n_layer": 24, "n_head": 16, "n_embd": 1024, "block_size": 1024, "vocab_size": 50257, "dropout": 0.0, "bias": true, "kv_cache_quant": false, "cross_layer_sharing": true}, "prompt_length": 32, "batch_size": 1, "seed": 1337, "pretrained": "gpt2-medium", "benchmark_name": "vram_vs_T", "version": "v3", "version_description": "KV-cache + cross-layer sharing", "use_cache": true, "kv_cache_quant": false, "cross_layer_sharing": true, "T": 320, "peak_memory_bytes": 820856832, "peak_activation_bytes": 51252736, "baseline_memory_bytes": 769604096}
{"implementation_name": "baseline", "gpu_name": "NVIDIA RTX A6000", "gpu_total_vram": 51033931776, "python_version": "3.11.14", "pytorch_version": "2.9.1+cu128", "cuda_version": "12.8", "dtype": "bfloat16", "model_config": {"n_layer": 24, "n_head": 16, "n_embd": 1024, "block_size": 1024, "vocab_size": 50257, "dropout": 0.0, "bias": true, "kv_cache_quant": false, "cross_layer_sharing": true}, "prompt_length": 32, "batch_size": 1, "seed": 1337, "pretrained": "gpt2-medium", "benchmark_name": "vram_vs_T", "version": "v3", "version_description": "KV-cache + cross-layer sharing", "use_cache": true, "kv_cache_quant": false, "cross_layer_sharing": true, "T": 384, "peak_memory_bytes": 820857344, "peak_activation_bytes": 51253248, "baseline_memory_bytes": 769604096}
{"implementation_name": "baseline", "gpu_name": "NVIDIA RTX A6000", "gpu_total_vram": 51033931776, "python_version": "3.11.14", "pytorch_version": "2.9.1+cu128", "cuda_version": "12.8", "dtype": "bfloat16", "model_config": {"n_layer": 24, "n_head": 16, "n_embd": 1024, "block_size": 1024, "vocab_size": 50257, "dropout": 0.0, "bias": true, "kv_cache_quant": false, "cross_layer_sharing": true}, "prompt_length": 32, "batch_size": 1, "seed": 1337, "pretrained": "gpt2-medium", "benchmark_name": "vram_vs_T", "version": "v3", "version_description": "KV-cache + cross-layer sharing", "use_cache": true, "kv_cache_quant": false, "cross_layer_sharing": true, "T": 448, "peak_memory_bytes": 820857856, "peak_activation_bytes": 51253760, "baseline_memory_bytes": 769604096}
{"implementation_name": "baseline", "gpu_name": "NVIDIA RTX A6000", "gpu_total_vram": 51033931776, "python_version": "3.11.14", "pytorch_version": "2.9.1+cu128", "cuda_version": "12.8", "dtype": "bfloat16", "model_config": {"n_layer": 24, "n_head": 16, "n_embd": 1024, "block_size": 1024, "vocab_size": 50257, "dropout": 0.0, "bias": true, "kv_cache_quant": false, "cross_layer_sharing": true}, "prompt_length": 32, "batch_size": 1, "seed": 1337, "pretrained": "gpt2-medium", "benchmark_name": "vram_vs_T", "version": "v3", "version_description": "KV-cache + cross-layer sharing", "use_cache": true, "kv_cache_quant": false, "cross_layer_sharing": true, "T": 512, "peak_memory_bytes": 820858368, "peak_activation_bytes": 51254272, "baseline_memory_bytes": 769604096}
{"implementation_name": "baseline", "gpu_name": "NVIDIA RTX A6000", "gpu_total_vram": 51033931776, "python_version": "3.11.14", "pytorch_version": "2.9.1+cu128", "cuda_version": "12.8", "dtype": "bfloat16", "model_config": {"n_layer": 24, "n_head": 16, "n_embd": 1024, "block_size": 1024, "vocab_size": 50257, "dropout": 0.0, "bias": true, "kv_cache_quant": false, "cross_layer_sharing": true}, "prompt_length": 32, "batch_size": 1, "seed": 1337, "pretrained": "gpt2-medium", "benchmark_name": "vram_vs_T", "version": "v3", "version_description": "KV-cache + cross-layer sharing", "use_cache": true, "kv_cache_quant": false, "cross_layer_sharing": true, "T": 640, "peak_memory_bytes": 820859392, "peak_activation_bytes": 51255296, "baseline_memory_bytes": 769604096}
{"implementation_name": "baseline", "gpu_name": "NVIDIA RTX A6000", "gpu_total_vram": 51033931776, "python_version": "3.11.14", "pytorch_version": "2.9.1+cu128", "cuda_version": "12.8", "dtype": "bfloat16", "model_config": {"n_layer": 24, "n_head": 16, "n_embd": 1024, "block_size": 1024, "vocab_size": 50257, "dropout": 0.0, "bias": true, "kv_cache_quant": false, "cross_layer_sharing": true}, "prompt_length": 32, "batch_size": 1, "seed": 1337, "pretrained": "gpt2-medium", "benchmark_name": "vram_vs_T", "version": "v3", "version_description": "KV-cache + cross-layer sharing", "use_cache": true, "kv_cache_quant": false, "cross_layer_sharing": true, "T": 768, "peak_memory_bytes": 820860416, "peak_activation_bytes": 51256320, "baseline_memory_bytes": 769604096}
{"implementation_name": "baseline", "gpu_name": "NVIDIA RTX A6000", "gpu_total_vram": 51033931776, "python_version": "3.11.14", "pytorch_version": "2.9.1+cu128", "cuda_version": "12.8", "dtype": "bfloat16", "model_config": {"n_layer": 24, "n_head": 16, "n_embd": 1024, "block_size": 1024, "vocab_size": 50257, "dropout": 0.0, "bias": true, "kv_cache_quant": false, "cross_layer_sharing": true}, "prompt_length": 32, "batch_size": 1, "seed": 1337, "pretrained": "gpt2-medium", "benchmark_name": "vram_vs_T", "version": "v3", "version_description": "KV-cache + cross-layer sharing", "use_cache": true, "kv_cache_quant": false, "cross_layer_sharing": true, "T": 896, "peak_memory_bytes": 820861440, "peak_activation_bytes": 51257344, "baseline_memory_bytes": 769604096}
{"implementation_name": "baseline", "gpu_name": "NVIDIA RTX A6000", "gpu_total_vram": 51033931776, "python_version": "3.11.14", "pytorch_version": "2.9.1+cu128", "cuda_version": "12.8", "dtype": "bfloat16", "model_config": {"n_layer": 24, "n_head": 16, "n_embd": 1024, "block_size": 1024, "vocab_size": 50257, "dropout": 0.0, "bias": true, "kv_cache_quant": false, "cross_layer_sharing": true}, "prompt_length": 32, "batch_size": 1, "seed": 1337, "pretrained": "gpt2-medium", "benchmark_name": "vram_vs_T", "version": "v3", "version_description": "KV-cache + cross-layer sharing", "use_cache": true, "kv_cache_quant": false, "cross_layer_sharing": true, "T": 1024, "peak_memory_bytes": 845313024, "peak_activation_bytes": 75708928, "baseline_memory_bytes": 769604096}
{"implementation_name": "baseline", "gpu_name": "NVIDIA RTX A6000", "gpu_total_vram": 51033931776, "python_version": "3.11.14", "pytorch_version": "2.9.1+cu128", "cuda_version": "12.8", "dtype": "bfloat16", "model_config": {"n_layer": 24, "n_head": 16, "n_embd": 1024, "block_size": 1024, "vocab_size": 50257, "dropout": 0.0, "bias": true, "kv_cache_quant": true, "cross_layer_sharing": true}, "prompt_length": 32, "batch_size": 1, "seed": 1337, "pretrained": "gpt2-medium", "benchmark_name": "vram_vs_T", "version": "v4", "version_description": "KV-cache + INT8 + cross-layer sharing", "use_cache": true, "kv_cache_quant": true, "cross_layer_sharing": true, "T": 32, "peak_memory_bytes": 795737600, "peak_activation_bytes": 26133504, "baseline_memory_bytes": 769604096}
{"implementation_name": "baseline", "gpu_name": "NVIDIA RTX A6000", "gpu_total_vram": 51033931776, "python_version": "3.11.14", "pytorch_version": "2.9.1+cu128", "cuda_version": "12.8", "dtype": "bfloat16", "model_config": {"n_layer": 24, "n_head": 16, "n_embd": 1024, "block_size": 1024, "vocab_size": 50257, "dropout": 0.0, "bias": true, "kv_cache_quant": true, "cross_layer_sharing": true}, "prompt_length": 32, "batch_size": 1, "seed": 1337, "pretrained": "gpt2-medium", "benchmark_name": "vram_vs_T", "version": "v4", "version_description": "KV-cache + INT8 + cross-layer sharing", "use_cache": true, "kv_cache_quant": true, "cross_layer_sharing": true, "T": 64, "peak_memory_bytes": 795738112, "peak_activation_bytes": 26134016, "baseline_memory_bytes": 769604096}
{"implementation_name": "baseline", "gpu_name": "NVIDIA RTX A6000", "gpu_total_vram": 51033931776, "python_version": "3.11.14", "pytorch_version": "2.9.1+cu128", "cuda_version": "12.8", "dtype": "bfloat16", "model_config": {"n_layer": 24, "n_head": 16, "n_embd": 1024, "block_size": 1024, "vocab_size": 50257, "dropout": 0.0, "bias": true, "kv_cache_quant": true, "cross_layer_sharing": true}, "prompt_length": 32, "batch_size": 1, "seed": 1337, "pretrained": "gpt2-medium", "benchmark_name": "vram_vs_T", "version": "v4", "version_description": "KV-cache + INT8 + cross-layer sharing", "use_cache": true, "kv_cache_quant": true, "cross_layer_sharing": true, "T": 96, "peak_memory_bytes": 795818496, "peak_activation_bytes": 26214400, "baseline_memory_bytes": 769604096}
{"implementation_name": "baseline", "gpu_name": "NVIDIA RTX A6000", "gpu_total_vram": 51033931776, "python_version": "3.11.14", "pytorch_version": "2.9.1+cu128", "cuda_version": "12.8", "dtype": "bfloat16", "model_config": {"n_layer": 24, "n_head": 16, "n_embd": 1024, "block_size": 1024, "vocab_size": 50257, "dropout": 0.0, "bias": true, "kv_cache_quant": true, "cross_layer_sharing": true}, "prompt_length": 32, "batch_size": 1, "seed": 1337, "pretrained": "gpt2-medium", "benchmark_name": "vram_vs_T", "version": "v4", "version_description": "KV-cache + INT8 + cross-layer sharing", "use_cache": true, "kv_cache_quant": true, "cross_layer_sharing": true, "T": 128, "peak_memory_bytes": 796015616, "peak_activation_bytes": 26411520, "baseline_memory_bytes": 769604096}
{"implementation_name": "baseline", "gpu_name": "NVIDIA RTX A6000", "gpu_total_vram": 51033931776, "python_version": "3.11.14", "pytorch_version": "2.9.1+cu128", "cuda_version": "12.8", "dtype": "bfloat16", "model_config": {"n_layer": 24, "n_head": 16, "n_embd": 1024, "block_size": 1024, "vocab_size": 50257, "dropout": 0.0, "bias": true, "kv_cache_quant": true, "cross_layer_sharing": true}, "prompt_length": 32, "batch_size": 1, "seed": 1337, "pretrained": "gpt2-medium", "benchmark_name": "vram_vs_T", "version": "v4", "version_description": "KV-cache + INT8 + cross-layer sharing", "use_cache": true, "kv_cache_quant": true, "cross_layer_sharing": true, "T": 160, "peak_memory_bytes": 796212224, "peak_activation_bytes": 26608128, "baseline_memory_bytes": 769604096}
{"implementation_name": "baseline", "gpu_name": "NVIDIA RTX A6000", "gpu_total_vram": 51033931776, "python_version": "3.11.14", "pytorch_version": "2.9.1+cu128", "cuda_version": "12.8", "dtype": "bfloat16", "model_config": {"n_layer": 24, "n_head": 16, "n_embd": 1024, "block_size": 1024, "vocab_size": 50257, "dropout": 0.0, "bias": true, "kv_cache_quant": true, "cross_layer_sharing": true}, "prompt_length": 32, "batch_size": 1, "seed": 1337, "pretrained": "gpt2-medium", "benchmark_name": "vram_vs_T", "version": "v4", "version_description": "KV-cache + INT8 + cross-layer sharing", "use_cache": true, "kv_cache_quant": true, "cross_layer_sharing": true, "T": 192, "peak_memory_bytes": 796409344, "peak_activation_bytes": 26805248, "baseline_memory_bytes": 769604096}
{"implementation_name": "baseline", "gpu_name": "NVIDIA RTX A6000", "gpu_total_vram": 51033931776, "python_version": "3.11.14", "pytorch_version": "2.9.1+cu128", "cuda_version": "12.8", "dtype": "bfloat16", "model_config": {"n_layer": 24, "n_head": 16, "n_embd": 1024, "block_size": 1024, "vocab_size": 50257, "dropout": 0.0, "bias": true, "kv_cache_quant": true, "cross_layer_sharing": true}, "prompt_length": 32, "batch_size": 1, "seed": 1337, "pretrained": "gpt2-medium", "benchmark_name": "vram_vs_T", "version": "v4", "version_description": "KV-cache + INT8 + cross-layer sharing", "use_cache": true, "kv_cache_quant": true, "cross_layer_sharing": true, "T": 224, "peak_memory_bytes": 796605952, "peak_activation_bytes": 27001856, "baseline_memory_bytes": 769604096}
{"implementation_name": "baseline", "gpu_name": "NVIDIA RTX A6000", "gpu_total_vram": 51033931776, "python_version": "3.11.14", "pytorch_version": "2.9.1+cu128", "cuda_version": "12.8", "dtype": "bfloat16", "model_config": {"n_layer": 24, "n_head": 16, "n_embd": 1024, "block_size": 1024, "vocab_size": 50257, "dropout": 0.0, "bias": true, "kv_cache_quant": true, "cross_layer_sharing": true}, "prompt_length": 32, "batch_size": 1, "seed": 1337, "pretrained": "gpt2-medium", "benchmark_name": "vram_vs_T", "version": "v4", "version_description": "KV-cache + INT8 + cross-layer sharing", "use_cache": true, "kv_cache_quant": true, "cross_layer_sharing": true, "T": 256, "peak_memory_bytes": 796803072, "peak_activation_bytes": 27198976, "baseline_memory_bytes": 769604096}
{"implementation_name": "baseline", "gpu_name": "NVIDIA RTX A6000", "gpu_total_vram": 51033931776, "python_version": "3.11.14", "pytorch_version": "2.9.1+cu128", "cuda_version": "12.8", "dtype": "bfloat16", "model_config": {"n_layer": 24, "n_head": 16, "n_embd": 1024, "block_size": 1024, "vocab_size": 50257, "dropout": 0.0, "bias": true, "kv_cache_quant": true, "cross_layer_sharing": true}, "prompt_length": 32, "batch_size": 1, "seed": 1337, "pretrained": "gpt2-medium", "benchmark_name": "vram_vs_T", "version": "v4", "version_description": "KV-cache + INT8 + cross-layer sharing", "use_cache": true, "kv_cache_quant": true, "cross_layer_sharing": true, "T": 320, "peak_memory_bytes": 797196800, "peak_activation_bytes": 27592704, "baseline_memory_bytes": 769604096}
{"implementation_name": "baseline", "gpu_name": "NVIDIA RTX A6000", "gpu_total_vram": 51033931776, "python_version": "3.11.14", "pytorch_version": "2.9.1+cu128", "cuda_version": "12.8", "dtype": "bfloat16", "model_config": {"n_layer": 24, "n_head": 16, "n_embd": 1024, "block_size": 1024, "vocab_size": 50257, "dropout": 0.0, "bias": true, "kv_cache_quant": true, "cross_layer_sharing": true}, "prompt_length": 32, "batch_size": 1, "seed": 1337, "pretrained": "gpt2-medium", "benchmark_name": "vram_vs_T", "version": "v4", "version_description": "KV-cache + INT8 + cross-layer sharing", "use_cache": true, "kv_cache_quant": true, "cross_layer_sharing": true, "T": 384, "peak_memory_bytes": 797590528, "peak_activation_bytes": 27986432, "baseline_memory_bytes": 769604096}
{"implementation_name": "baseline", "gpu_name": "NVIDIA RTX A6000", "gpu_total_vram": 51033931776, "python_version": "3.11.14", "pytorch_version": "2.9.1+cu128", "cuda_version": "12.8", "dtype": "bfloat16", "model_config": {"n_layer": 24, "n_head": 16, "n_embd": 1024, "block_size": 1024, "vocab_size": 50257, "dropout": 0.0, "bias": true, "kv_cache_quant": true, "cross_layer_sharing": true}, "prompt_length": 32, "batch_size": 1, "seed": 1337, "pretrained": "gpt2-medium", "benchmark_name": "vram_vs_T", "version": "v4", "version_description": "KV-cache + INT8 + cross-layer sharing", "use_cache": true, "kv_cache_quant": true, "cross_layer_sharing": true, "T": 448, "peak_memory_bytes": 797984256, "peak_activation_bytes": 28380160, "baseline_memory_bytes": 769604096}
{"implementation_name": "baseline", "gpu_name": "NVIDIA RTX A6000", "gpu_total_vram": 51033931776, "python_version": "3.11.14", "pytorch_version": "2.9.1+cu128", "cuda_version": "12.8", "dtype": "bfloat16", "model_config": {"n_layer": 24, "n_head": 16, "n_embd": 1024, "block_size": 1024, "vocab_size": 50257, "dropout": 0.0, "bias": true, "kv_cache_quant": true, "cross_layer_sharing": true}, "prompt_length": 32, "batch_size": 1, "seed": 1337, "pretrained": "gpt2-medium", "benchmark_name": "vram_vs_T", "version": "v4", "version_description": "KV-cache + INT8 + cross-layer sharing", "use_cache": true, "kv_cache_quant": true, "cross_layer_sharing": true, "T": 512, "peak_memory_bytes": 800051200, "peak_activation_bytes": 30447104, "baseline_memory_bytes": 769604096}
{"implementation_name": "baseline", "gpu_name": "NVIDIA RTX A6000", "gpu_total_vram": 51033931776, "python_version": "3.11.14", "pytorch_version": "2.9.1+cu128", "cuda_version": "12.8", "dtype": "bfloat16", "model_config": {"n_layer": 24, "n_head": 16, "n_embd": 1024, "block_size": 1024, "vocab_size": 50257, "dropout": 0.0, "bias": true, "kv_cache_quant": true, "cross_layer_sharing": true}, "prompt_length": 32, "batch_size": 1, "seed": 1337, "pretrained": "gpt2-medium", "benchmark_name": "vram_vs_T", "version": "v4", "version_description": "KV-cache + INT8 + cross-layer sharing", "use_cache": true, "kv_cache_quant": true, "cross_layer_sharing": true, "T": 640, "peak_memory_bytes": 800314368, "peak_activation_bytes": 30710272, "baseline_memory_bytes": 769604096}
{"implementation_name": "baseline", "gpu_name": "NVIDIA RTX A6000", "gpu_total_vram": 51033931776, "python_version": "3.11.14", "pytorch_version": "2.9.1+cu128", "cuda_version": "12.8", "dtype": "bfloat16", "model_config": {"n_layer": 24, "n_head": 16, "n_embd": 1024, "block_size": 1024, "vocab_size": 50257, "dropout": 0.0, "bias": true, "kv_cache_quant": true, "cross_layer_sharing": true}, "prompt_length": 32, "batch_size": 1, "seed": 1337, "pretrained": "gpt2-medium", "benchmark_name": "vram_vs_T", "version": "v4", "version_description": "KV-cache + INT8 + cross-layer sharing", "use_cache": true, "kv_cache_quant": true, "cross_layer_sharing": true, "T": 768, "peak_memory_bytes": 800577536, "peak_activation_bytes": 30973440, "baseline_memory_bytes": 769604096}
{"implementation_name": "baseline", "gpu_name": "NVIDIA RTX A6000", "gpu_total_vram": 51033931776, "python_version": "3.11.14", "pytorch_version": "2.9.1+cu128", "cuda_version": "12.8", "dtype": "bfloat16", "model_config": {"n_layer": 24, "n_head": 16, "n_embd": 1024, "block_size": 1024, "vocab_size": 50257, "dropout": 0.0, "bias": true, "kv_cache_quant": true, "cross_layer_sharing": true}, "prompt_length": 32, "batch_size": 1, "seed": 1337, "pretrained": "gpt2-medium", "benchmark_name": "vram_vs_T", "version": "v4", "version_description": "KV-cache + INT8 + cross-layer sharing", "use_cache": true, "kv_cache_quant": true, "cross_layer_sharing": true, "T": 896, "peak_memory_bytes": 800840704, "peak_activation_bytes": 31236608, "baseline_memory_bytes": 769604096}
{"implementation_name": "baseline", "gpu_name": "NVIDIA RTX A6000", "gpu_total_vram": 51033931776, "python_version": "3.11.14", "pytorch_version": "2.9.1+cu128", "cuda_version": "12.8", "dtype": "bfloat16", "model_config": {"n_layer": 24, "n_head": 16, "n_embd": 1024, "block_size": 1024, "vocab_size": 50257, "dropout": 0.0, "bias": true, "kv_cache_quant": true, "cross_layer_sharing": true}, "prompt_length": 32, "batch_size": 1, "seed": 1337, "pretrained": "gpt2-medium", "benchmark_name": "vram_vs_T", "version": "v4", "version_description": "KV-cache + INT8 + cross-layer sharing", "use_cache": true, "kv_cache_quant": true, "cross_layer_sharing": true, "T": 1024, "peak_memory_bytes": 807601152, "peak_activation_bytes": 37997056, "baseline_memory_bytes": 769604096}
{"implementation_name": "baseline", "gpu_name": "NVIDIA RTX A6000", "gpu_total_vram": 51033931776, "python_version": "3.11.14", "pytorch_version": "2.9.1+cu128", "cuda_version": "12.8", "dtype": "bfloat16", "model_config": {"n_layer": 24, "n_head": 16, "n_embd": 1024, "block_size": 1024, "vocab_size": 50257, "dropout": 0.0, "bias": true, "kv_cache_quant": false, "cross_layer_sharing": false}, "prompt_length": 32, "batch_size": 1, "seed": 1337, "pretrained": "gpt2-medium", "benchmark_name": "per_phase_timing", "version": "v0", "version_description": "No cache (baseline)", "use_cache": false, "kv_cache_quant": false, "cross_layer_sharing": false, "T_star": 512, "time_phase_ms": {"embedding": 6.55075216293335, "attention": 1018.7092895507812, "mlp": 1181.22265625, "head": 84.00198364257812, "total": 2678.84033203125, "other": 388.3556504249573}}
{"implementation_name": "baseline", "gpu_name": "NVIDIA RTX A6000", "gpu_total_vram": 51033931776, "python_version": "3.11.14", "pytorch_version": "2.9.1+cu128", "cuda_version": "12.8", "dtype": "bfloat16", "model_config": {"n_layer": 24, "n_head": 16, "n_embd": 1024, "block_size": 1024, "vocab_size": 50257, "dropout": 0.0, "bias": true, "kv_cache_quant": false, "cross_layer_sharing": false}, "prompt_length": 32, "batch_size": 1, "seed": 1337, "pretrained": "gpt2-medium", "benchmark_name": "per_phase_timing", "version": "v1", "version_description": "KV-cache enabled", "use_cache": true, "kv_cache_quant": false, "cross_layer_sharing": false, "T_star": 512, "time_phase_ms": {"embedding": 5.693312168121338, "attention": 970.6073608398438, "mlp": 588.507568359375, "head": 82.75504302978516, "total": 2318.66162109375, "other": 671.0983366966248}}
{"implementation_name": "baseline", "gpu_name": "NVIDIA RTX A6000", "gpu_total_vram": 51033931776, "python_version": "3.11.14", "pytorch_version": "2.9.1+cu128", "cuda_version": "12.8", "dtype": "bfloat16", "model_config": {"n_layer": 24, "n_head": 16, "n_embd": 1024, "block_size": 1024, "vocab_size": 50257, "dropout": 0.0, "bias": true, "kv_cache_quant": true, "cross_layer_sharing": false}, "prompt_length": 32, "batch_size": 1, "seed": 1337, "pretrained": "gpt2-medium", "benchmark_name": "per_phase_timing", "version": "v2", "version_description": "KV-cache + INT8 quantization", "use_cache": true, "kv_cache_quant": true, "cross_layer_sharing": false, "T_star": 512, "time_phase_ms": {"embedding": 5.630335807800293, "attention": 2791.3310546875, "mlp": 637.7927856445312, "head": 83.67715454101562, "total": 4206.78564453125, "other": 688.3543138504028}}
{"implementation_name": "baseline", "gpu_name": "NVIDIA RTX A6000", "gpu_total_vram": 51033931776, "python_version": "3.11.14", "pytorch_version": "2.9.1+cu128", "cuda_version": "12.8", "dtype": "bfloat16", "model_config": {"n_layer": 24, "n_head": 16, "n_embd": 1024, "block_size": 1024, "vocab_size": 50257, "dropout": 0.0, "bias": true, "kv_cache_quant": false, "cross_layer_sharing": true}, "prompt_length": 32, "batch_size": 1, "seed": 1337, "pretrained": "gpt2-medium", "benchmark_name": "per_phase_timing", "version": "v3", "version_description": "KV-cache + cross-layer sharing", "use_cache": true, "kv_cache_quant": false, "cross_layer_sharing": true, "T_star": 512, "time_phase_ms": {"embedding": 5.698624134063721, "attention": 859.0458984375, "mlp": 591.3250732421875, "head": 82.72358703613281, "total": 2208.092041015625, "other": 669.298858165741}}
{"implementation_name": "baseline", "gpu_name": "NVIDIA RTX A6000", "gpu_total_vram": 51033931776, "python_version": "3.11.14", "pytorch_version": "2.9.1+cu128", "cuda_version": "12.8", "dtype": "bfloat16", "model_config": {"n_layer": 24, "n_head": 16, "n_embd": 1024, "block_size": 1024, "vocab_size": 50257, "dropout": 0.0, "bias": true, "kv_cache_quant": true, "cross_layer_sharing": true}, "prompt_length": 32, "batch_size": 1, "seed": 1337, "pretrained": "gpt2-medium", "benchmark_name": "per_phase_timing", "version": "v4", "version_description": "KV-cache + INT8 + cross-layer sharing", "use_cache": true, "kv_cache_quant": true, "cross_layer_sharing": true, "T_star": 512, "time_phase_ms": {"embedding": 5.642848014831543, "attention": 2031.22265625, "mlp": 632.0845336914062, "head": 83.62105560302734, "total": 3410.35009765625, "other": 657.7790040969849}}
{"implementation_name": "baseline", "gpu_name": "NVIDIA RTX A6000", "gpu_total_vram": 51033931776, "python_version": "3.11.14", "pytorch_version": "2.9.1+cu128", "cuda_version": "12.8", "dtype": "bfloat16", "model_config": {"n_layer": 24, "n_head": 16, "n_embd": 1024, "block_size": 1024, "vocab_size": 50257, "dropout": 0.0, "bias": true, "kv_cache_quant": false, "cross_layer_sharing": false}, "prompt_length": 32, "batch_size": 1, "seed": 1337, "pretrained": "gpt2-medium", "benchmark_name": "max_batch_capacity", "version": "v0", "version_description": "No cache (baseline)", "use_cache": false, "kv_cache_quant": false, "cross_layer_sharing": false, "capacity_T": 128, "max_batch_size": 7586, "peak_memory_bytes": 34432246272, "peak_memory_gb": 34.432246272}
{"implementation_name": "baseline", "gpu_name": "NVIDIA RTX A6000", "gpu_total_vram": 51033931776, "python_version": "3.11.14", "pytorch_version": "2.9.1+cu128", "cuda_version": "12.8", "dtype": "bfloat16", "model_config": {"n_layer": 24, "n_head": 16, "n_embd": 1024, "block_size": 1024, "vocab_size": 50257, "dropout": 0.0, "bias": true, "kv_cache_quant": false, "cross_layer_sharing": false}, "prompt_length": 32, "batch_size": 1, "seed": 1337, "pretrained": "gpt2-medium", "benchmark_name": "max_batch_capacity", "version": "v1", "version_description": "KV-cache enabled", "use_cache": true, "kv_cache_quant": false, "cross_layer_sharing": false, "capacity_T": 128, "max_batch_size": 491, "peak_memory_bytes": 50615691776, "peak_memory_gb": 50.615691776}
{"implementation_name": "baseline", "gpu_name": "NVIDIA RTX A6000", "gpu_total_vram": 51033931776, "python_version": "3.11.14", "pytorch_version": "2.9.1+cu128", "cuda_version": "12.8", "dtype": "bfloat16", "model_config": {"n_layer": 24, "n_head": 16, "n_embd": 1024, "block_size": 1024, "vocab_size": 50257, "dropout": 0.0, "bias": true, "kv_cache_quant": true, "cross_layer_sharing": false}, "prompt_length": 32, "batch_size": 1, "seed": 1337, "pretrained": "gpt2-medium", "benchmark_name": "max_batch_capacity", "version": "v2", "version_description": "KV-cache + INT8 quantization", "use_cache": true, "kv_cache_quant": true, "cross_layer_sharing": false, "capacity_T": 128, "max_batch_size": 962, "peak_memory_bytes": 50338140672, "peak_memory_gb": 50.338140672}
{"implementation_name": "baseline", "gpu_name": "NVIDIA RTX A6000", "gpu_total_vram": 51033931776, "python_version": "3.11.14", "pytorch_version": "2.9.1+cu128", "cuda_version": "12.8", "dtype": "bfloat16", "model_config": {"n_layer": 24, "n_head": 16, "n_embd": 1024, "block_size": 1024, "vocab_size": 50257, "dropout": 0.0, "bias": true, "kv_cache_quant": false, "cross_layer_sharing": true}, "prompt_length": 32, "batch_size": 1, "seed": 1337, "pretrained": "gpt2-medium", "benchmark_name": "max_batch_capacity", "version": "v3", "version_description": "KV-cache + cross-layer sharing", "use_cache": true, "kv_cache_quant": false, "cross_layer_sharing": true, "capacity_T": 128, "max_batch_size": 970, "peak_memory_bytes": 50421922304, "peak_memory_gb": 50.421922304}
{"implementation_name": "baseline", "gpu_name": "NVIDIA RTX A6000", "gpu_total_vram": 51033931776, "python_version": "3.11.14", "pytorch_version": "2.9.1+cu128", "cuda_version": "12.8", "dtype": "bfloat16", "model_config": {"n_layer": 24, "n_head": 16, "n_embd": 1024, "block_size": 1024, "vocab_size": 50257, "dropout": 0.0, "bias": true, "kv_cache_quant": true, "cross_layer_sharing": true}, "prompt_length": 32, "batch_size": 1, "seed": 1337, "pretrained": "gpt2-medium", "benchmark_name": "max_batch_capacity", "version": "v4", "version_description": "KV-cache + INT8 + cross-layer sharing", "use_cache": true, "kv_cache_quant": true, "cross_layer_sharing": true, "capacity_T": 128, "max_batch_size": 1867, "peak_memory_bytes": 49982542848, "peak_memory_gb": 49.982542848}
{"implementation_name": "baseline", "gpu_name": "NVIDIA RTX A6000", "gpu_total_vram": 51033931776, "python_version": "3.11.14", "pytorch_version": "2.9.1+cu128", "cuda_version": "12.8", "dtype": "bfloat16", "model_config": {"n_layer": 24, "n_head": 16, "n_embd": 1024, "block_size": 1024, "vocab_size": 50257, "dropout": 0.0, "bias": true, "kv_cache_quant": false, "cross_layer_sharing": false}, "pretrained": "gpt2-medium", "benchmark_name": "perplexity", "version": "v0", "version_description": "No cache (baseline)", "use_cache": false, "kv_cache_quant": false, "cross_layer_sharing": false, "dataset": "wikitext-2", "eval_mode": "autoregressive", "stride": null, "num_tokens_evaluated": 287643, "perplexity": 18.174371304220006, "loss": 2.9000124315816778}
{"implementation_name": "baseline", "gpu_name": "NVIDIA RTX A6000", "gpu_total_vram": 51033931776, "python_version": "3.11.14", "pytorch_version": "2.9.1+cu128", "cuda_version": "12.8", "dtype": "bfloat16", "model_config": {"n_layer": 24, "n_head": 16, "n_embd": 1024, "block_size": 1024, "vocab_size": 50257, "dropout": 0.0, "bias": true, "kv_cache_quant": false, "cross_layer_sharing": false}, "pretrained": "gpt2-medium", "benchmark_name": "perplexity", "version": "v1", "version_description": "KV-cache enabled", "use_cache": true, "kv_cache_quant": false, "cross_layer_sharing": false, "dataset": "wikitext-2", "eval_mode": "autoregressive", "stride": null, "num_tokens_evaluated": 287643, "perplexity": 710.8235629902415, "loss": 6.566424245689182}
{"implementation_name": "baseline", "gpu_name": "NVIDIA RTX A6000", "gpu_total_vram": 51033931776, "python_version": "3.11.14", "pytorch_version": "2.9.1+cu128", "cuda_version": "12.8", "dtype": "bfloat16", "model_config": {"n_layer": 24, "n_head": 16, "n_embd": 1024, "block_size": 1024, "vocab_size": 50257, "dropout": 0.0, "bias": true, "kv_cache_quant": true, "cross_layer_sharing": false}, "pretrained": "gpt2-medium", "benchmark_name": "perplexity", "version": "v2", "version_description": "KV-cache + INT8 quantization", "use_cache": true, "kv_cache_quant": true, "cross_layer_sharing": false, "dataset": "wikitext-2", "eval_mode": "autoregressive", "stride": null, "num_tokens_evaluated": 287643, "perplexity": 711.4897198864103, "loss": 6.567360968917319}
{"implementation_name": "baseline", "gpu_name": "NVIDIA RTX A6000", "gpu_total_vram": 51033931776, "python_version": "3.11.14", "pytorch_version": "2.9.1+cu128", "cuda_version": "12.8", "dtype": "bfloat16", "model_config": {"n_layer": 24, "n_head": 16, "n_embd": 1024, "block_size": 1024, "vocab_size": 50257, "dropout": 0.0, "bias": true, "kv_cache_quant": false, "cross_layer_sharing": true}, "pretrained": "gpt2-medium", "benchmark_name": "perplexity", "version": "v3", "version_description": "KV-cache + cross-layer sharing", "use_cache": true, "kv_cache_quant": false, "cross_layer_sharing": true, "dataset": "wikitext-2", "eval_mode": "autoregressive", "stride": null, "num_tokens_evaluated": 287643, "perplexity": 5474.299189829961, "loss": 8.607819544634223}
{"implementation_name": "baseline", "gpu_name": "NVIDIA RTX A6000", "gpu_total_vram": 51033931776, "python_version": "3.11.14", "pytorch_version": "2.9.1+cu128", "cuda_version": "12.8", "dtype": "bfloat16", "model_config": {"n_layer": 24, "n_head": 16, "n_embd": 1024, "block_size": 1024, "vocab_size": 50257, "dropout": 0.0, "bias": true, "kv_cache_quant": true, "cross_layer_sharing": true}, "pretrained": "gpt2-medium", "benchmark_name": "perplexity", "version": "v4", "version_description": "KV-cache + INT8 + cross-layer sharing", "use_cache": true, "kv_cache_quant": true, "cross_layer_sharing": true, "dataset": "wikitext-2", "eval_mode": "autoregressive", "stride": null, "num_tokens_evaluated": 287643, "perplexity": 5497.464165641911, "loss": 8.612042204106974}
{"implementation_name": "baseline", "gpu_name": "NVIDIA RTX A6000", "gpu_total_vram": 51033931776, "python_version": "3.11.14", "pytorch_version": "2.9.1+cu128", "cuda_version": "12.8", "dtype": "bfloat16", "model_config": {"n_layer": 24, "n_head": 16, "n_embd": 1024, "block_size": 1024, "vocab_size": 50257, "dropout": 0.0, "bias": true, "kv_cache_quant": false, "cross_layer_sharing": false}, "pretrained": "gpt2-medium", "benchmark_name": "perplexity", "version": "v1", "version_description": "KV-cache enabled", "use_cache": true, "kv_cache_quant": false, "cross_layer_sharing": false, "dataset": "wikitext-2", "eval_mode": "autoregressive", "stride": null, "num_tokens_evaluated": 287643, "perplexity": 710.8235629902415, "loss": 6.566424245689182}
{"implementation_name": "baseline", "gpu_name": "NVIDIA RTX A6000", "gpu_total_vram": 51033931776, "python_version": "3.11.14", "pytorch_version": "2.9.1+cu128", "cuda_version": "12.8", "dtype": "bfloat16", "model_config": {"n_layer": 24, "n_head": 16, "n_embd": 1024, "block_size": 1024, "vocab_size": 50257, "dropout": 0.0, "bias": true, "kv_cache_quant": false, "cross_layer_sharing": true}, "pretrained": "gpt2-medium", "benchmark_name": "perplexity", "version": "v3", "version_description": "KV-cache + cross-layer sharing", "use_cache": true, "kv_cache_quant": false, "cross_layer_sharing": true, "dataset": "wikitext-2", "eval_mode": "autoregressive", "stride": null, "num_tokens_evaluated": 287643, "perplexity": 5474.299189829961, "loss": 8.607819544634223}
{"implementation_name": "baseline", "gpu_name": "NVIDIA RTX A6000", "gpu_total_vram": 51033931776, "python_version": "3.11.14", "pytorch_version": "2.9.1+cu128", "cuda_version": "12.8", "dtype": "bfloat16", "model_config": {"n_layer": 24, "n_head": 16, "n_embd": 1024, "block_size": 1024, "vocab_size": 50257, "dropout": 0.0, "bias": true, "kv_cache_quant": false, "cross_layer_sharing": true}, "pretrained": "gpt2-medium", "benchmark_name": "perplexity", "version": "v3a", "version_description": "[EXP] Cross-layer + Q-aligned", "use_cache": true, "kv_cache_quant": false, "cross_layer_sharing": true, "dataset": "wikitext-2", "eval_mode": "autoregressive", "stride": null, "num_tokens_evaluated": 287643, "perplexity": 2142.5737073900054, "loss": 7.669763052395937}
{"implementation_name": "baseline", "gpu_name": "NVIDIA RTX A6000", "gpu_total_vram": 51033931776, "python_version": "3.11.14", "pytorch_version": "2.9.1+cu128", "cuda_version": "12.8", "dtype": "bfloat16", "model_config": {"n_layer": 24, "n_head": 16, "n_embd": 1024, "block_size": 1024, "vocab_size": 50257, "dropout": 0.0, "bias": true, "kv_cache_quant": false, "cross_layer_sharing": false}, "pretrained": "gpt2-medium", "benchmark_name": "perplexity", "version": "v0", "version_description": "No cache (baseline)", "use_cache": false, "kv_cache_quant": false, "cross_layer_sharing": false, "dataset": "wikitext-2", "eval_mode": "autoregressive", "stride": null, "num_tokens_evaluated": 4999, "perplexity": 20.02677695967256, "loss": 2.9970702260798228}
{"implementation_name": "baseline", "gpu_name": "NVIDIA RTX A6000", "gpu_total_vram": 51033931776, "python_version": "3.11.14", "pytorch_version": "2.9.1+cu128", "cuda_version": "12.8", "dtype": "bfloat16", "model_config": {"n_layer": 24, "n_head": 16, "n_embd": 1024, "block_size": 1024, "vocab_size": 50257, "dropout": 0.0, "bias": true, "kv_cache_quant": false, "cross_layer_sharing": false}, "pretrained": "gpt2-medium", "benchmark_name": "perplexity", "version": "v0", "version_description": "No cache (baseline)", "use_cache": false, "kv_cache_quant": false, "cross_layer_sharing": false, "dataset": "wikitext-2", "eval_mode": "autoregressive", "stride": null, "num_tokens_evaluated": 4999, "perplexity": 20.02677695967256, "loss": 2.9970702260798228}
{"implementation_name": "baseline", "gpu_name": "NVIDIA RTX A6000", "gpu_total_vram": 51033931776, "python_version": "3.11.14", "pytorch_version": "2.9.1+cu128", "cuda_version": "12.8", "dtype": "bfloat16", "model_config": {"n_layer": 24, "n_head": 16, "n_embd": 1024, "block_size": 1024, "vocab_size": 50257, "dropout": 0.0, "bias": true, "kv_cache_quant": false, "cross_layer_sharing": false}, "pretrained": "gpt2-medium", "benchmark_name": "perplexity", "version": "v1", "version_description": "KV-cache enabled", "use_cache": true, "kv_cache_quant": false, "cross_layer_sharing": false, "dataset": "wikitext-2", "eval_mode": "autoregressive", "stride": null, "num_tokens_evaluated": 4999, "perplexity": 328.1628342271381, "loss": 5.793509931010135}
{"implementation_name": "baseline", "gpu_name": "NVIDIA RTX A6000", "gpu_total_vram": 51033931776, "python_version": "3.11.14", "pytorch_version": "2.9.1+cu128", "cuda_version": "12.8", "dtype": "bfloat16", "model_config": {"n_layer": 24, "n_head": 16, "n_embd": 1024, "block_size": 1024, "vocab_size": 50257, "dropout": 0.0, "bias": true, "kv_cache_quant": false, "cross_layer_sharing": false}, "pretrained": "gpt2-medium", "benchmark_name": "perplexity", "version": "v1", "version_description": "KV-cache enabled", "use_cache": true, "kv_cache_quant": false, "cross_layer_sharing": false, "dataset": "wikitext-2", "eval_mode": "autoregressive", "stride": null, "num_tokens_evaluated": 99, "perplexity": 31.650078239926785, "loss": 3.454740620622731}
{"implementation_name": "baseline", "gpu_name": "NVIDIA RTX A6000", "gpu_total_vram": 51033931776, "python_version": "3.11.14", "pytorch_version": "2.9.1+cu128", "cuda_version": "12.8", "dtype": "bfloat16", "model_config": {"n_layer": 24, "n_head": 16, "n_embd": 1024, "block_size": 1024, "vocab_size": 50257, "dropout": 0.0, "bias": true, "kv_cache_quant": false, "cross_layer_sharing": false}, "pretrained": "gpt2-medium", "benchmark_name": "perplexity", "version": "v0", "version_description": "No cache (baseline)", "use_cache": false, "kv_cache_quant": false, "cross_layer_sharing": false, "dataset": "wikitext-2", "eval_mode": "autoregressive", "stride": null, "num_tokens_evaluated": 1999, "perplexity": 16.1905106941784, "loss": 2.784425310995532}
{"implementation_name": "baseline", "gpu_name": "NVIDIA RTX A6000", "gpu_total_vram": 51033931776, "python_version": "3.11.14", "pytorch_version": "2.9.1+cu128", "cuda_version": "12.8", "dtype": "bfloat16", "model_config": {"n_layer": 24, "n_head": 16, "n_embd": 1024, "block_size": 1024, "vocab_size": 50257, "dropout": 0.0, "bias": true, "kv_cache_quant": false, "cross_layer_sharing": false}, "pretrained": "gpt2-medium", "benchmark_name": "perplexity", "version": "v1", "version_description": "KV-cache enabled", "use_cache": true, "kv_cache_quant": false, "cross_layer_sharing": false, "dataset": "wikitext-2", "eval_mode": "autoregressive", "stride": null, "num_tokens_evaluated": 1999, "perplexity": 76.75688741004303, "loss": 4.3406431206826745}
{"implementation_name": "baseline", "gpu_name": "NVIDIA RTX A6000", "gpu_total_vram": 51033931776, "python_version": "3.11.14", "pytorch_version": "2.9.1+cu128", "cuda_version": "12.8", "dtype": "bfloat16", "model_config": {"n_layer": 24, "n_head": 16, "n_embd": 1024, "block_size": 1024, "vocab_size": 50257, "dropout": 0.0, "bias": true, "kv_cache_quant": true, "cross_layer_sharing": false}, "pretrained": "gpt2-medium", "benchmark_name": "perplexity", "version": "v2", "version_description": "KV-cache + INT8 quantization", "use_cache": true, "kv_cache_quant": true, "cross_layer_sharing": false, "dataset": "wikitext-2", "eval_mode": "autoregressive", "stride": null, "num_tokens_evaluated": 1999, "perplexity": 76.31778387733814, "loss": 4.3349059894718245}
{"implementation_name": "baseline", "gpu_name": "NVIDIA RTX A6000", "gpu_total_vram": 51033931776, "python_version": "3.11.14", "pytorch_version": "2.9.1+cu128", "cuda_version": "12.8", "dtype": "bfloat16", "model_config": {"n_layer": 24, "n_head": 16, "n_embd": 1024, "block_size": 1024, "vocab_size": 50257, "dropout": 0.0, "bias": true, "kv_cache_quant": false, "cross_layer_sharing": true}, "pretrained": "gpt2-medium", "benchmark_name": "perplexity", "version": "v3", "version_description": "KV-cache + cross-layer sharing", "use_cache": true, "kv_cache_quant": false, "cross_layer_sharing": true, "dataset": "wikitext-2", "eval_mode": "autoregressive", "stride": null, "num_tokens_evaluated": 1999, "perplexity": 2375.2063712177696, "loss": 7.772839605838075}
{"implementation_name": "baseline", "gpu_name": "NVIDIA RTX A6000", "gpu_total_vram": 51033931776, "python_version": "3.11.14", "pytorch_version": "2.9.1+cu128", "cuda_version": "12.8", "dtype": "bfloat16", "model_config": {"n_layer": 24, "n_head": 16, "n_embd": 1024, "block_size": 1024, "vocab_size": 50257, "dropout": 0.0, "bias": true, "kv_cache_quant": true, "cross_layer_sharing": true}, "pretrained": "gpt2-medium", "benchmark_name": "perplexity", "version": "v4", "version_description": "KV-cache + INT8 + cross-layer sharing", "use_cache": true, "kv_cache_quant": true, "cross_layer_sharing": true, "dataset": "wikitext-2", "eval_mode": "autoregressive", "stride": null, "num_tokens_evaluated": 1999, "perplexity": 2409.1323303295253, "loss": 7.7870219327498225}
{"implementation_name": "baseline", "gpu_name": "NVIDIA RTX A6000", "gpu_total_vram": 51033931776, "python_version": "3.11.14", "pytorch_version": "2.9.1+cu128", "cuda_version": "12.8", "dtype": "bfloat16", "model_config": {"n_layer": 24, "n_head": 16, "n_embd": 1024, "block_size": 1024, "vocab_size": 50257, "dropout": 0.0, "bias": true, "kv_cache_quant": true, "cross_layer_sharing": true}, "pretrained": "gpt2-medium", "benchmark_name": "perplexity", "version": "v4a", "version_description": "[EXP] Cross-layer + INT8 + Q-aligned", "use_cache": true, "kv_cache_quant": true, "cross_layer_sharing": true, "dataset": "wikitext-2", "eval_mode": "autoregressive", "stride": null, "num_tokens_evaluated": 287643, "perplexity": 2151.3525208644314, "loss": 7.673852002805991}
{"implementation_name": "baseline", "gpu_name": "NVIDIA RTX A6000", "gpu_total_vram": 51033931776, "python_version": "3.11.14", "pytorch_version": "2.9.1+cu128", "cuda_version": "12.8", "dtype": "bfloat16", "model_config": {"n_layer": 24, "n_head": 16, "n_embd": 1024, "block_size": 1024, "vocab_size": 50257, "dropout": 0.0, "bias": true, "kv_cache_quant": false, "cross_layer_sharing": false}, "pretrained": "gpt2-medium", "benchmark_name": "perplexity", "version": "v0", "version_description": "No cache (baseline)", "use_cache": false, "kv_cache_quant": false, "cross_layer_sharing": false, "dataset": "wikitext-2", "eval_mode": "autoregressive", "stride": null, "num_tokens_evaluated": 4095, "perplexity": 21.764905557496007, "loss": 3.0802988358033008}
{"implementation_name": "baseline", "gpu_name": "NVIDIA RTX A6000", "gpu_total_vram": 51033931776, "python_version": "3.11.14", "pytorch_version": "2.9.1+cu128", "cuda_version": "12.8", "dtype": "bfloat16", "model_config": {"n_layer": 24, "n_head": 16, "n_embd": 1024, "block_size": 1024, "vocab_size": 50257, "dropout": 0.0, "bias": true, "kv_cache_quant": false, "cross_layer_sharing": false}, "pretrained": "gpt2-medium", "benchmark_name": "perplexity", "version": "v1", "version_description": "KV-cache enabled", "use_cache": true, "kv_cache_quant": false, "cross_layer_sharing": false, "dataset": "wikitext-2", "eval_mode": "autoregressive", "stride": null, "num_tokens_evaluated": 4095, "perplexity": 21.71958018468303, "loss": 3.078214166365264}
{"implementation_name": "baseline", "gpu_name": "NVIDIA RTX A6000", "gpu_total_vram": 51033931776, "python_version": "3.11.14", "pytorch_version": "2.9.1+cu128", "cuda_version": "12.8", "dtype": "bfloat16", "model_config": {"n_layer": 24, "n_head": 16, "n_embd": 1024, "block_size": 1024, "vocab_size": 50257, "dropout": 0.0, "bias": true, "kv_cache_quant": true, "cross_layer_sharing": false}, "pretrained": "gpt2-medium", "benchmark_name": "perplexity", "version": "v2", "version_description": "KV-cache + INT8 quantization", "use_cache": true, "kv_cache_quant": true, "cross_layer_sharing": false, "dataset": "wikitext-2", "eval_mode": "autoregressive", "stride": null, "num_tokens_evaluated": 4095, "perplexity": 21.7285073614964, "loss": 3.0786251016879986}
{"implementation_name": "baseline", "gpu_name": "NVIDIA RTX A6000", "gpu_total_vram": 51033931776, "python_version": "3.11.14", "pytorch_version": "2.9.1+cu128", "cuda_version": "12.8", "dtype": "bfloat16", "model_config": {"n_layer": 24, "n_head": 16, "n_embd": 1024, "block_size": 1024, "vocab_size": 50257, "dropout": 0.0, "bias": true, "kv_cache_quant": false, "cross_layer_sharing": true}, "pretrained": "gpt2-medium", "benchmark_name": "perplexity", "version": "v3", "version_description": "KV-cache + cross-layer sharing", "use_cache": true, "kv_cache_quant": false, "cross_layer_sharing": true, "dataset": "wikitext-2", "eval_mode": "autoregressive", "stride": null, "num_tokens_evaluated": 4095, "perplexity": 779.9047699507329, "loss": 6.659171822423318}
{"implementation_name": "baseline", "gpu_name": "NVIDIA RTX A6000", "gpu_total_vram": 51033931776, "python_version": "3.11.14", "pytorch_version": "2.9.1+cu128", "cuda_version": "12.8", "dtype": "bfloat16", "model_config": {"n_layer": 24, "n_head": 16, "n_embd": 1024, "block_size": 1024, "vocab_size": 50257, "dropout": 0.0, "bias": true, "kv_cache_quant": false, "cross_layer_sharing": true}, "pretrained": "gpt2-medium", "benchmark_name": "perplexity", "version": "v3a", "version_description": "[EXP] Cross-layer + Q-aligned", "use_cache": true, "kv_cache_quant": false, "cross_layer_sharing": true, "dataset": "wikitext-2", "eval_mode": "autoregressive", "stride": null, "num_tokens_evaluated": 4095, "perplexity": 116.87618453970093, "loss": 4.761115122656537}
{"implementation_name": "baseline", "gpu_name": "NVIDIA RTX A6000", "gpu_total_vram": 51033931776, "python_version": "3.11.14", "pytorch_version": "2.9.1+cu128", "cuda_version": "12.8", "dtype": "bfloat16", "model_config": {"n_layer": 24, "n_head": 16, "n_embd": 1024, "block_size": 1024, "vocab_size": 50257, "dropout": 0.0, "bias": true, "kv_cache_quant": true, "cross_layer_sharing": true}, "pretrained": "gpt2-medium", "benchmark_name": "perplexity", "version": "v4", "version_description": "KV-cache + INT8 + cross-layer sharing", "use_cache": true, "kv_cache_quant": true, "cross_layer_sharing": true, "dataset": "wikitext-2", "eval_mode": "autoregressive", "stride": null, "num_tokens_evaluated": 4095, "perplexity": 782.9374887440238, "loss": 6.6630528572278145}
{"implementation_name": "baseline", "gpu_name": "NVIDIA RTX A6000", "gpu_total_vram": 51033931776, "python_version": "3.11.14", "pytorch_version": "2.9.1+cu128", "cuda_version": "12.8", "dtype": "bfloat16", "model_config": {"n_layer": 24, "n_head": 16, "n_embd": 1024, "block_size": 1024, "vocab_size": 50257, "dropout": 0.0, "bias": true, "kv_cache_quant": true, "cross_layer_sharing": true}, "pretrained": "gpt2-medium", "benchmark_name": "perplexity", "version": "v4a", "version_description": "[EXP] Cross-layer + INT8 + Q-aligned", "use_cache": true, "kv_cache_quant": true, "cross_layer_sharing": true, "dataset": "wikitext-2", "eval_mode": "autoregressive", "stride": null, "num_tokens_evaluated": 4095, "perplexity": 116.92175277755433, "loss": 4.761504931385846}
{"implementation_name": "baseline", "gpu_name": "NVIDIA RTX A6000", "gpu_total_vram": 51033931776, "python_version": "3.11.14", "pytorch_version": "2.9.1+cu128", "cuda_version": "12.8", "dtype": "bfloat16", "model_config": {"n_layer": 24, "n_head": 16, "n_embd": 1024, "block_size": 1024, "vocab_size": 50257, "dropout": 0.0, "bias": true, "kv_cache_quant": false, "cross_layer_sharing": false}, "pretrained": "gpt2-medium", "benchmark_name": "perplexity", "version": "v0", "version_description": "No cache (baseline)", "use_cache": false, "kv_cache_quant": false, "cross_layer_sharing": false, "dataset": "wikitext-2", "eval_mode": "autoregressive", "stride": null, "num_tokens_evaluated": 16383, "perplexity": 22.601957352898353, "loss": 3.118036511063263}
{"implementation_name": "baseline", "gpu_name": "NVIDIA RTX A6000", "gpu_total_vram": 51033931776, "python_version": "3.11.14", "pytorch_version": "2.9.1+cu128", "cuda_version": "12.8", "dtype": "bfloat16", "model_config": {"n_layer": 24, "n_head": 16, "n_embd": 1024, "block_size": 1024, "vocab_size": 50257, "dropout": 0.0, "bias": true, "kv_cache_quant": false, "cross_layer_sharing": false}, "pretrained": "gpt2-medium", "benchmark_name": "perplexity", "version": "v1", "version_description": "KV-cache enabled", "use_cache": true, "kv_cache_quant": false, "cross_layer_sharing": false, "dataset": "wikitext-2", "eval_mode": "autoregressive", "stride": null, "num_tokens_evaluated": 16383, "perplexity": 22.53859898262928, "loss": 3.1152293497423313}
{"implementation_name": "baseline", "gpu_name": "NVIDIA RTX A6000", "gpu_total_vram": 51033931776, "python_version": "3.11.14", "pytorch_version": "2.9.1+cu128", "cuda_version": "12.8", "dtype": "bfloat16", "model_config": {"n_layer": 24, "n_head": 16, "n_embd": 1024, "block_size": 1024, "vocab_size": 50257, "dropout": 0.0, "bias": true, "kv_cache_quant": true, "cross_layer_sharing": false}, "pretrained": "gpt2-medium", "benchmark_name": "perplexity", "version": "v2", "version_description": "KV-cache + INT8 quantization", "use_cache": true, "kv_cache_quant": true, "cross_layer_sharing": false, "dataset": "wikitext-2", "eval_mode": "autoregressive", "stride": null, "num_tokens_evaluated": 16383, "perplexity": 22.582414434653142, "loss": 3.1171714810234197}
{"implementation_name": "baseline", "gpu_name": "NVIDIA RTX A6000", "gpu_total_vram": 51033931776, "python_version": "3.11.14", "pytorch_version": "2.9.1+cu128", "cuda_version": "12.8", "dtype": "bfloat16", "model_config": {"n_layer": 24, "n_head": 16, "n_embd": 1024, "block_size": 1024, "vocab_size": 50257, "dropout": 0.0, "bias": true, "kv_cache_quant": false, "cross_layer_sharing": true}, "pretrained": "gpt2-medium", "benchmark_name": "perplexity", "version": "v3a", "version_description": "[EXP] Cross-layer + Q-aligned", "use_cache": true, "kv_cache_quant": false, "cross_layer_sharing": true, "dataset": "wikitext-2", "eval_mode": "autoregressive", "stride": null, "num_tokens_evaluated": 16383, "perplexity": 141.1675024522665, "loss": 4.949947145965622}
{"implementation_name": "baseline", "gpu_name": "NVIDIA RTX A6000", "gpu_total_vram": 51033931776, "python_version": "3.11.14", "pytorch_version": "2.9.1+cu128", "cuda_version": "12.8", "dtype": "bfloat16", "model_config": {"n_layer": 24, "n_head": 16, "n_embd": 1024, "block_size": 1024, "vocab_size": 50257, "dropout": 0.0, "bias": true, "kv_cache_quant": true, "cross_layer_sharing": true}, "pretrained": "gpt2-medium", "benchmark_name": "perplexity", "version": "v4a", "version_description": "[EXP] Cross-layer + INT8 + Q-aligned", "use_cache": true, "kv_cache_quant": true, "cross_layer_sharing": true, "dataset": "wikitext-2", "eval_mode": "autoregressive", "stride": null, "num_tokens_evaluated": 16383, "perplexity": 141.31514159865162, "loss": 4.950992443175468}
{"implementation_name": "baseline", "gpu_name": "NVIDIA RTX A6000", "gpu_total_vram": 51033931776, "python_version": "3.11.14", "pytorch_version": "2.9.1+cu128", "cuda_version": "12.8", "dtype": "bfloat16", "model_config": {"n_layer": 24, "n_head": 16, "n_embd": 1024, "block_size": 1024, "vocab_size": 50257, "dropout": 0.0, "bias": true, "kv_cache_quant": false, "cross_layer_sharing": true}, "pretrained": "gpt2-medium", "benchmark_name": "perplexity", "version": "v3", "version_description": "KV-cache + cross-layer sharing", "use_cache": true, "kv_cache_quant": false, "cross_layer_sharing": true, "dataset": "wikitext-2", "eval_mode": "autoregressive", "stride": null, "num_tokens_evaluated": 16383, "perplexity": 988.7589551234837, "loss": 6.89645057605575}
{"implementation_name": "baseline", "gpu_name": "NVIDIA RTX A6000", "gpu_total_vram": 51033931776, "python_version": "3.11.14", "pytorch_version": "2.9.1+cu128", "cuda_version": "12.8", "dtype": "bfloat16", "model_config": {"n_layer": 24, "n_head": 16, "n_embd": 1024, "block_size": 1024, "vocab_size": 50257, "dropout": 0.0, "bias": true, "kv_cache_quant": true, "cross_layer_sharing": true}, "pretrained": "gpt2-medium", "benchmark_name": "perplexity", "version": "v4", "version_description": "KV-cache + INT8 + cross-layer sharing", "use_cache": true, "kv_cache_quant": true, "cross_layer_sharing": true, "dataset": "wikitext-2", "eval_mode": "autoregressive", "stride": null, "num_tokens_evaluated": 16383, "perplexity": 997.0912628614717, "loss": 6.904842303246433}
